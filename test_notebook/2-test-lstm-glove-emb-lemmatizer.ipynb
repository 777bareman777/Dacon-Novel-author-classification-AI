{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufcGB_euCc7M"
   },
   "source": [
    "## 라이브러리 import 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:45:46.691781Z",
     "start_time": "2020-11-11T08:45:46.374124Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:45:49.092670Z",
     "start_time": "2020-11-11T08:45:49.044571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:45:49.142073Z",
     "start_time": "2020-11-11T08:45:49.094891Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 로드 및 GloVe 임베딩 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://nlp.stanford.edu/data/glove.6B.zip 를 다운받아 `data_dir`에 압축을 푼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:45:49.188294Z",
     "start_time": "2020-11-11T08:45:49.143955Z"
    },
    "id": "0ZwTCLUOCtUu"
   },
   "outputs": [],
   "source": [
    "data_dir = Path('../data/dacon-novel-author-classification')\n",
    "feature_dir = Path('../build/feature')\n",
    "val_dir = Path('../build/val')\n",
    "tst_dir = Path('../build/tst')\n",
    "sub_dir = Path('../build/sub')\n",
    "\n",
    "dirs = [feature_dir, val_dir, tst_dir, sub_dir]\n",
    "for d in dirs:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "glove_file = data_dir / 'glove.6B.100d.txt'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:45:49.232577Z",
     "start_time": "2020-11-11T08:45:49.190101Z"
    }
   },
   "outputs": [],
   "source": [
    "algo_name = 'lstm'\n",
    "feature_name = 'lemmatization-glove-emb'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "sub_file = sub_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(f'wget http://nlp.stanford.edu/data/glove.6B.zip -P {data_dir}')\n",
    "# os.system(f'unzip {data_dir}/glove.6B.zip -d {data_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:45:55.949438Z",
     "start_time": "2020-11-11T08:45:49.234527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "print(f'Found {len(embeddings_index)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:45:56.143188Z",
     "start_time": "2020-11-11T08:45:55.952700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "SvX_U2ETC7vA",
    "outputId": "25b26c45-fe51-42b4-b55d-eaddea79fd94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      He was almost choking. There was so much, so m...       3\n",
       "1                 “Your sister asked for it, I suppose?”       2\n",
       "2       She was engaged one day as she walked, in per...       1\n",
       "3      The captain was in the porch, keeping himself ...       4\n",
       "4      “Have mercy, gentlemen!” odin flung up his han...       3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = pd.read_csv(trn_file, index_col=0)\n",
    "print(trn.shape)\n",
    "trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:45:56.272321Z",
     "start_time": "2020-11-11T08:45:56.145651Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "8MxZsr6yCshr",
    "outputId": "e8a76d96-2fde-4796-be03-7e3cdf4f9ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19617, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Not at all. I think she is one of the most ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the lady had stated her intention of scream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“And then suddenly in the silence I heard a so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His conviction remained unchanged. So far as I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "index                                                   \n",
       "0      “Not at all. I think she is one of the most ch...\n",
       "1      \"No,\" replied he, with sudden consciousness, \"...\n",
       "2      As the lady had stated her intention of scream...\n",
       "3      “And then suddenly in the silence I heard a so...\n",
       "4      His conviction remained unchanged. So far as I..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = pd.read_csv(tst_file, index_col=0)\n",
    "print(tst.shape)\n",
    "tst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPq0vxJVDS3R"
   },
   "source": [
    "## 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#부호를 제거해주는 함수\n",
    "def alpha_num(text):\n",
    "    return re.sub(r\"[^A-Za-z0-9' ]\", '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 적용\n",
    "trn['text'] = trn['text'].str.lower()\n",
    "tst['text'] = tst['text'].str.lower()\n",
    "\n",
    "trn['text'] = trn['text'].apply(alpha_num)\n",
    "tst['text'] = tst['text'].apply(alpha_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 품사 정보를 이용해서 표제어 추출\n",
    "\n",
    "# 단어의 품사 정보 얻는 함수\n",
    "def get_wordnet_pos(word):\n",
    "    if word.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif word.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif word.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif word.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# 품사 정보를 이용해서 표제어 추출하는 함수\n",
    "def get_lemmatization(docs):\n",
    "    transformed_docs = list()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for sentence in docs:\n",
    "        words = word_tokenize(sentence)\n",
    "        pos_tagged = pos_tag(words)\n",
    "        wordnet_tagged = list(map(lambda x: (x[0], get_wordnet_pos(x[1])), pos_tagged))\n",
    "        \n",
    "        lemmatized_word = []\n",
    "        for word, tag in wordnet_tagged:\n",
    "            if tag is None:\n",
    "                lemmatized_word.append(word)\n",
    "            else:\n",
    "                lemmatized_word.append(lemmatizer.lemmatize(word,tag))\n",
    "        transformed_docs.append(lemmatized_word)\n",
    "    return transformed_docs\n",
    "\n",
    "trn_doc = get_lemmatization(trn['text'])\n",
    "tst_doc = get_lemmatization(tst['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879,) (19617,) (54879,)\n"
     ]
    }
   ],
   "source": [
    "# train test 분리\n",
    "X_trn= np.array([\" \".join(i) for i in trn_doc])\n",
    "X_tst = np.array([\" \".join(i) for i in tst_doc])\n",
    "y = np.array([x for x in trn['author']])\n",
    "print(X_trn.shape, X_tst.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['he be almost choke there be so much so much he want to say but strange exclamation be all that come from his lip the pole gaze fixedly at him at the bundle of note in his hand look at odin and be in evident perplexity',\n",
       "       'your sister ask for it i suppose',\n",
       "       'she be engage one day as she walk in peruse janes last letter and dwelling on some passage which prove that jane have not write in spirit when instead of be again surprise by mr odin she saw on look up that odin be meet her put away the letter immediately and force a smile she say',\n",
       "       ..., 'your sincere wellwisher friend and sister lucy odin',\n",
       "       'then you want me to lend you money',\n",
       "       'it certainly have not occur to me before but i say yes i should like that'],\n",
       "      dtype='<U2342')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:46:04.089851Z",
     "start_time": "2020-11-11T08:46:02.832120Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKj4SmSIDtM3",
    "outputId": "c195fb8c-dec3-42d9-9e57-442aa64ec7e7"
   },
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=500)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_trn).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:46:04.156059Z",
     "start_time": "2020-11-11T08:46:04.091791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'be', 'and']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:46:04.221462Z",
     "start_time": "2020-11-11T08:46:04.157642Z"
    }
   },
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:46:04.293723Z",
     "start_time": "2020-11-11T08:46:04.223267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 16694 words (3306 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(f\"Converted {hits} words ({misses} misses)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:46:04.334509Z",
     "start_time": "2020-11-11T08:46:04.295465Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks1FhSNUHrke"
   },
   "source": [
    "## 케라스 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:46:04.375162Z",
     "start_time": "2020-11-11T08:46:04.336325Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:46:24.944052Z",
     "start_time": "2020-11-11T08:46:24.900870Z"
    },
    "id": "U2CxfUPZEOu0"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    int_sequences_input = Input(shape=(1,), dtype=tf.string)\n",
    "    vectorized_sequences = vectorizer(int_sequences_input)\n",
    "    embedded_sequences = embedding_layer(vectorized_sequences)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(embedded_sequences)\n",
    "    x = Bidirectional(LSTM(64))(x)\n",
    "    preds = Dense(n_class, activation=\"softmax\")(x)\n",
    "    model = Model(int_sequences_input, preds)\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:02:53.164754Z",
     "start_time": "2020-11-11T08:46:25.126129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 18s 214ms/step - loss: 1.4451 - val_loss: 1.2350\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 16s 190ms/step - loss: 1.0914 - val_loss: 1.0028\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 17s 193ms/step - loss: 0.9110 - val_loss: 0.9391\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 16s 190ms/step - loss: 0.7905 - val_loss: 0.8225\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 16s 188ms/step - loss: 0.7132 - val_loss: 0.8219\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 15s 175ms/step - loss: 0.6256 - val_loss: 0.8228\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.5586 - val_loss: 0.7978\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 15s 172ms/step - loss: 0.4973 - val_loss: 0.8646\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.4436 - val_loss: 0.8986\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.3850Restoring model weights from the end of the best epoch.\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.3850 - val_loss: 0.9150\n",
      "Epoch 00010: early stopping\n",
      "training model for CV #2\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 16s 190ms/step - loss: 1.3679 - val_loss: 1.1569\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 1.0445 - val_loss: 0.9878\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 15s 175ms/step - loss: 0.8791 - val_loss: 0.8707\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.7555 - val_loss: 0.8172\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.6818 - val_loss: 0.8141\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.5917 - val_loss: 0.8036\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.5092 - val_loss: 0.8254\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.4507 - val_loss: 0.8843\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.3884Restoring model weights from the end of the best epoch.\n",
      "86/86 [==============================] - 15s 175ms/step - loss: 0.3884 - val_loss: 0.9020\n",
      "Epoch 00009: early stopping\n",
      "training model for CV #3\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 16s 188ms/step - loss: 1.3813 - val_loss: 1.1356\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 1.1585 - val_loss: 1.0509\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.9627 - val_loss: 0.9066\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 15s 175ms/step - loss: 0.8168 - val_loss: 0.8198\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.7116 - val_loss: 0.8033\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.6352 - val_loss: 0.7727\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.5554 - val_loss: 0.7933\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.4968 - val_loss: 0.8063\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.4335Restoring model weights from the end of the best epoch.\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.4335 - val_loss: 0.8556\n",
      "Epoch 00009: early stopping\n",
      "training model for CV #4\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 16s 189ms/step - loss: 1.3760 - val_loss: 1.1665\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 15s 171ms/step - loss: 1.0487 - val_loss: 0.9770\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.8749 - val_loss: 0.8645\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 15s 172ms/step - loss: 0.7575 - val_loss: 0.8221\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.6681 - val_loss: 0.8091\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 15s 172ms/step - loss: 0.5794 - val_loss: 0.8018\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.5140 - val_loss: 0.8395\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 15s 172ms/step - loss: 0.4514 - val_loss: 0.8527\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.3950Restoring model weights from the end of the best epoch.\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.3950 - val_loss: 0.9204\n",
      "Epoch 00009: early stopping\n",
      "training model for CV #5\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 16s 189ms/step - loss: 1.4162 - val_loss: 1.2062\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 1.0831 - val_loss: 1.0595\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 15s 175ms/step - loss: 0.9018 - val_loss: 0.8789\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.7710 - val_loss: 0.8432\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.6691 - val_loss: 0.8162\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 15s 173ms/step - loss: 0.5918 - val_loss: 0.8033\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 15s 175ms/step - loss: 0.5114 - val_loss: 0.8100\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 15s 174ms/step - loss: 0.4524 - val_loss: 0.8633\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.3988Restoring model weights from the end of the best epoch.\n",
      "86/86 [==============================] - 15s 175ms/step - loss: 0.3988 - val_loss: 0.9028\n",
      "Epoch 00009: early stopping\n",
      "Training has finished\n",
      "****************************************************************************************************\n",
      "Accuracy (CV):  70.6536%\n",
      "Log Loss (CV):   0.7958\n"
     ]
    }
   ],
   "source": [
    "p_val = np.zeros((X_trn.shape[0], n_class))\n",
    "p_tst = np.zeros((X_tst.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_trn, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "    \n",
    "    clf = get_model() \n",
    "    clf.fit(X_trn[i_trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=(X_trn[i_val], to_categorical(y[i_val])),\n",
    "            epochs=10,\n",
    "            batch_size=512,\n",
    "            callbacks=[es])\n",
    "    p_val[i_val, :] = clf.predict(X_trn[i_val])\n",
    "    p_tst += clf.predict(X_tst) / n_fold\n",
    "\n",
    "print(\"Training has finished\")\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
    "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:02:53.174427Z",
     "start_time": "2020-11-11T08:46:27.472Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxUTpZnPEXJX",
    "outputId": "02c9e1f2-439d-48a3-f78e-27fb6932ef72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 500, 100)          2000200   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 500, 128)          84480     \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,184,141\n",
      "Trainable params: 183,941\n",
      "Non-trainable params: 2,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출 파일 생성 및 기타 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:02:53.178318Z",
     "start_time": "2020-11-11T08:46:29.408Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jXKoOWIC6g0",
    "outputId": "620417f7-087d-4f0f-e6c6-34af5484880c"
   },
   "outputs": [],
   "source": [
    "# submission 파일 생성\n",
    "\n",
    "sub = pd.read_csv(sample_file, index_col=0)\n",
    "sub[sub.columns] = p_tst\n",
    "sub.to_csv(sub_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:02:53.180270Z",
     "start_time": "2020-11-11T08:46:29.625Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4S8eUx5FDFO",
    "outputId": "e31d03c3-b143-4922-ccb6-a6f9fcf02efc"
   },
   "outputs": [],
   "source": [
    "# p_val 파일 생성 -> oof\n",
    "\n",
    "np.savetxt(p_val_file, p_val, fmt='%.18f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:02:53.182248Z",
     "start_time": "2020-11-11T08:46:30.305Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "tZhbUjhXE3Yr",
    "outputId": "6642ce6e-22c5-4f87-a4f1-5bdae56abaad"
   },
   "outputs": [],
   "source": [
    "# p_tst 파일 생성 -> test \n",
    "\n",
    "np.savetxt(p_tst_file, p_tst, fmt='%.18f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "sample_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
