{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCxH-zh7Cbhb",
    "outputId": "14dccbb3-c489-48f2-cea9-bf1bd3b774ab"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OEZtMdB5CaDG"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "SvX_U2ETC7vA",
    "outputId": "86226a20-f1c1-4497-a4f5-c547f903696a"
   },
   "outputs": [],
   "source": [
    "data_dir = Path('../data/dacon-novel-author-classification')\n",
    "feature_dir = Path('../build/feature')\n",
    "val_dir = Path('../build/val')\n",
    "tst_dir = Path('../build/tst')\n",
    "sub_dir = Path('../build/sub')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "8MxZsr6yCshr",
    "outputId": "3b8de9f6-c2d8-48d2-e44d-9d3c230dd407"
   },
   "outputs": [],
   "source": [
    "algo_name = 'lstm'\n",
    "feature_name = 'lemmatization-emb'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "sub_file = sub_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "WOpmyyX_77Op",
    "outputId": "ddff2b94-6ab2-4f3a-ae9d-ac36942bdb8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      He was almost choking. There was so much, so m...       3\n",
       "1                 “Your sister asked for it, I suppose?”       2\n",
       "2       She was engaged one day as she walked, in per...       1\n",
       "3      The captain was in the porch, keeping himself ...       4\n",
       "4      “Have mercy, gentlemen!” odin flung up his han...       3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = pd.read_csv(trn_file, index_col=0)\n",
    "print(trn.shape)\n",
    "trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19617, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Not at all. I think she is one of the most ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the lady had stated her intention of scream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“And then suddenly in the silence I heard a so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His conviction remained unchanged. So far as I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "index                                                   \n",
       "0      “Not at all. I think she is one of the most ch...\n",
       "1      \"No,\" replied he, with sudden consciousness, \"...\n",
       "2      As the lady had stated her intention of scream...\n",
       "3      “And then suddenly in the silence I heard a so...\n",
       "4      His conviction remained unchanged. So far as I..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = pd.read_csv(tst_file, index_col=0)\n",
    "print(tst.shape)\n",
    "tst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPq0vxJVDS3R"
   },
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tMUMcInsD80p"
   },
   "outputs": [],
   "source": [
    "#부호를 제거해주는 함수\n",
    "def alpha_num(text):\n",
    "    return re.sub(r\"[^A-Za-z0-9' ]\", '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sUgcc07ADiiU"
   },
   "outputs": [],
   "source": [
    "#전처리 적용\n",
    "trn['text'] = trn['text'].str.lower()\n",
    "tst['text'] = tst['text'].str.lower()\n",
    "\n",
    "trn['text'] = trn['text'].apply(alpha_num)\n",
    "tst['text'] = tst['text'].apply(alpha_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 품사 정보를 이용해서 표제어 추출\n",
    "\n",
    "# 단어의 품사 정보 얻는 함수\n",
    "def get_wordnet_pos(word):\n",
    "    if word.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif word.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif word.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif word.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# 품사 정보를 이용해서 표제어 추출하는 함수\n",
    "def get_lemmatization(docs):\n",
    "    transformed_docs = list()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for sentence in docs:\n",
    "        words = word_tokenize(sentence)\n",
    "        pos_tagged = pos_tag(words)\n",
    "        wordnet_tagged = list(map(lambda x: (x[0], get_wordnet_pos(x[1])), pos_tagged))\n",
    "        \n",
    "        lemmatized_word = []\n",
    "        for word, tag in wordnet_tagged:\n",
    "            if tag is None:\n",
    "                lemmatized_word.append(word)\n",
    "            else:\n",
    "                lemmatized_word.append(lemmatizer.lemmatize(word,tag))\n",
    "        transformed_docs.append(lemmatized_word)\n",
    "    return transformed_docs\n",
    "\n",
    "trn_doc = get_lemmatization(trn['text'])\n",
    "tst_doc = get_lemmatization(tst['text'])\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# trn_doc = list()\n",
    "# for sentence in trn['text']:\n",
    "#     words = word_tokenize(sentence)\n",
    "#     lemmatized_words = [lemmatizer.lemmatize(t, get_wordnet_pos(t)) for t in words]\n",
    "#     trn_doc.append(lemmatized_words)\n",
    "    \n",
    "# tst_doc = list()\n",
    "# for sentence in tst['text']:\n",
    "#     words = word_tokenize(sentence)\n",
    "#     lemmatized_words = [lemmatizer.lemmatize(t, get_wordnet_pos(t)) for t in words]\n",
    "#     tst_doc.append(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train test 분리\n",
    "X_train= np.array([\" \".join(i) for i in trn_doc])\n",
    "X_test = np.array([\" \".join(i) for i in tst_doc])\n",
    "y_train = np.array([x for x in trn['author']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['he be almost choke there be so much so much he want to say but strange exclamation be all that come from his lip the pole gaze fixedly at him at the bundle of note in his hand look at odin and be in evident perplexity',\n",
       "       'your sister ask for it i suppose',\n",
       "       'she be engage one day as she walk in peruse janes last letter and dwelling on some passage which prove that jane have not write in spirit when instead of be again surprise by mr odin she saw on look up that odin be meet her put away the letter immediately and force a smile she say',\n",
       "       ..., 'your sincere wellwisher friend and sister lucy odin',\n",
       "       'then you want me to lend you money',\n",
       "       'it certainly have not occur to me before but i say yes i should like that'],\n",
       "      dtype='<U2342')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks1FhSNUHrke"
   },
   "source": [
    "# **모델링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "um6uZK5EDzAm"
   },
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "vocab_size = 30000\n",
    "embedding_dim = 128\n",
    "max_length = 500\n",
    "padding_type='post'\n",
    "#oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UvR9_VnTD8L9"
   },
   "outputs": [],
   "source": [
    "#tokenizer에 fit\n",
    "tokenizer = Tokenizer(num_words = vocab_size)#, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZQPwyZt0EEHW"
   },
   "outputs": [],
   "source": [
    "#데이터를 sequence로 변환해주고 padding 해줍니다.\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PGxdNonaWC2N"
   },
   "outputs": [],
   "source": [
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "U2CxfUPZEOu0"
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.0001, patience=7, verbose=1, mode='min',\n",
    "    #model 학습시 5 epoch이상 loss 지표가 낮아지지 않을 경우 early stop을 해준다.\n",
    "    baseline=None, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxUTpZnPEXJX",
    "outputId": "a6180511-3f56-47a8-be37-78d29087e1b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 128)          3840000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 500, 256)          263168    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 4,596,741\n",
      "Trainable params: 4,596,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51YtSBBiEcMv",
    "outputId": "5a5efc61-23bd-4505-c899-ef372e3f17b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1372/1372 [==============================] - 155s 113ms/step - loss: 1.0967 - accuracy: 0.5642 - val_loss: 0.8859 - val_accuracy: 0.6628\n",
      "Epoch 2/200\n",
      "1372/1372 [==============================] - 153s 112ms/step - loss: 0.7609 - accuracy: 0.7209 - val_loss: 0.7315 - val_accuracy: 0.7355\n",
      "Epoch 3/200\n",
      "1372/1372 [==============================] - 153s 112ms/step - loss: 0.6489 - accuracy: 0.7694 - val_loss: 0.7253 - val_accuracy: 0.7423\n",
      "Epoch 4/200\n",
      "1372/1372 [==============================] - 153s 112ms/step - loss: 0.5807 - accuracy: 0.7956 - val_loss: 0.6703 - val_accuracy: 0.7627\n",
      "Epoch 5/200\n",
      "1372/1372 [==============================] - 154s 112ms/step - loss: 0.5297 - accuracy: 0.8159 - val_loss: 0.6789 - val_accuracy: 0.7593\n",
      "Epoch 6/200\n",
      "1372/1372 [==============================] - 154s 112ms/step - loss: 0.4888 - accuracy: 0.8318 - val_loss: 0.7254 - val_accuracy: 0.7573\n",
      "Epoch 7/200\n",
      "1372/1372 [==============================] - 154s 112ms/step - loss: 0.4535 - accuracy: 0.8463 - val_loss: 0.7724 - val_accuracy: 0.7625\n",
      "Epoch 8/200\n",
      "1372/1372 [==============================] - 153s 112ms/step - loss: 0.4195 - accuracy: 0.8581 - val_loss: 0.7496 - val_accuracy: 0.7630\n",
      "Epoch 9/200\n",
      "1372/1372 [==============================] - 153s 112ms/step - loss: 0.3859 - accuracy: 0.8711 - val_loss: 0.7956 - val_accuracy: 0.7664\n",
      "Epoch 10/200\n",
      "1372/1372 [==============================] - 153s 112ms/step - loss: 0.3559 - accuracy: 0.8809 - val_loss: 0.8872 - val_accuracy: 0.7575\n",
      "Epoch 11/200\n",
      "1372/1372 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.8929Restoring model weights from the end of the best epoch.\n",
      "1372/1372 [==============================] - 153s 111ms/step - loss: 0.3273 - accuracy: 0.8929 - val_loss: 0.9662 - val_accuracy: 0.7586\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "num_epochs = 200\n",
    "history = model.fit(train_padded, y_train, \n",
    "                    epochs=num_epochs, verbose=1, callbacks=[es],\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3jXKoOWIC6g0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-9e01c6cf1b05>:2: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n"
     ]
    }
   ],
   "source": [
    "# predict values\n",
    "pred = model.predict_proba(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "F4S8eUx5FDFO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.90020762e-02, 6.55193806e-01, 2.71328539e-01, 4.41987254e-02,\n",
       "        1.02768140e-02],\n",
       "       [1.48093119e-01, 3.93888623e-01, 1.54965362e-02, 3.56710739e-02,\n",
       "        4.06850666e-01],\n",
       "       [9.94663239e-01, 2.85558240e-03, 3.82325816e-04, 1.24360586e-03,\n",
       "        8.55244580e-04],\n",
       "       ...,\n",
       "       [6.33520528e-07, 9.99999285e-01, 1.95397742e-09, 7.56607861e-08,\n",
       "        1.50890678e-08],\n",
       "       [2.85093301e-05, 9.99966145e-01, 1.16811066e-07, 2.12656937e-06,\n",
       "        3.05416393e-06],\n",
       "       [9.73700702e-01, 8.16983450e-03, 3.62500455e-03, 6.78708777e-03,\n",
       "        7.71729741e-03]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tZhbUjhXE3Yr"
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "sub = pd.read_csv(sample_file,index_col=0)\n",
    "sub[sub.columns] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.3939</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.4069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9778</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4\n",
       "index                                        \n",
       "0      0.0190  0.6552  0.2713  0.0442  0.0103\n",
       "1      0.1481  0.3939  0.0155  0.0357  0.4069\n",
       "2      0.9947  0.0029  0.0004  0.0012  0.0009\n",
       "3      0.0001  0.0016  0.9976  0.0006  0.0002\n",
       "4      0.9778  0.0071  0.0018  0.0043  0.0090"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Xu8Wb207FP-D"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SokcUCL5FW8I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of [코드]_데이콘_기초_베이스라인_LSTM[11_12 edit].ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
