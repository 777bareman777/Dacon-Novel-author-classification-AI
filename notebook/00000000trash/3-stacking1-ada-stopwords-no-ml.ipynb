{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/dacon-novel-author-classification')\n",
    "feature_dir = Path('../build/feature')\n",
    "val_dir = Path('../build/val')\n",
    "tst_dir = Path('../build/tst')\n",
    "sub_dir = Path('../build/sub')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_name = 'ada'\n",
    "feature_name = 'stacking-layer1-stopwords-no-ml'\n",
    "model_name = f'{algorithm_name}_{feature_name}'\n",
    "\n",
    "feature_target_file = feature_dir / f'feature_target.csv'\n",
    "\n",
    "stacking_oof_pred_file = val_dir / f'{model_name}_oof_pred.csv'\n",
    "stacking_test_pred_file = tst_dir / f'{model_name}_test_pred.csv'\n",
    "stacking_submission_file = sub_dir / f'{model_name}_submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking feature 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature(model_names, number_of_ver=None, kind=None):\n",
    "    oof_list = []\n",
    "    test_list = []\n",
    "    \n",
    "    if number_of_ver==None or kind==None:\n",
    "        print('error')\n",
    "        return None\n",
    "    \n",
    "    # 딥러닝 시리즈 4가지 버전\n",
    "    if kind == 0:\n",
    "        for model in model_names:\n",
    "            print(f'load {model}_cv')\n",
    "            for i in range(1,number_of_ver+1):\n",
    "                oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv', delimiter=','))\n",
    "                test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "    \n",
    "    # 로지스틱 회귀 6가지 버전\n",
    "    elif kind == 1:\n",
    "        for model in model_names:\n",
    "            print(f'load {model}_cv')\n",
    "            for i in range(1, number_of_ver+1):\n",
    "                oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv', delimiter=','))\n",
    "                test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "\n",
    "    # 신경망 기반 불용어 처리 21가지 버전 또는 머신러닝 기반 불용어 처리 18가지 버전\n",
    "    elif kind == 2:\n",
    "        for model in model_names:\n",
    "            print(f'load {model}_cv')\n",
    "            if model.find('feature') != -1:\n",
    "                for i in range(2,5):\n",
    "                    oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv',delimiter=','))\n",
    "                    test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "            elif model.find('tfidf') != -1:\n",
    "                for i in range(1,4):\n",
    "                    oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv',delimiter=','))\n",
    "                    test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "            elif model.find('hashing') != -1:\n",
    "                for i in range(1,4):\n",
    "                    oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv',delimiter=','))\n",
    "                    test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "            elif model.find('bow') != -1:\n",
    "                for i in range(1,4):\n",
    "                    oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv',delimiter=','))\n",
    "                    test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "    \n",
    "    # 신경만 기반 불용어 처리 X 13가지 버전 또는 머신러닝 기반 불용어 처리 X 18가지 버전\n",
    "    elif kind == 3:\n",
    "        for model in model_names:\n",
    "            print(f'load {model}_cv')\n",
    "            if model.find('feature') != -1:\n",
    "                for i in range(1,2):\n",
    "                    oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv',delimiter=','))\n",
    "                    test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "            elif model.find('tfidf') != -1:\n",
    "                for i in range(3,6):\n",
    "                    oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv',delimiter=','))\n",
    "                    test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "            elif model.find('hashing') != -1:\n",
    "                for i in range(3,6):\n",
    "                    oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv',delimiter=','))\n",
    "                    test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "            elif model.find('bow') != -1:\n",
    "                for i in range(3,6):\n",
    "                    oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver{i}.csv',delimiter=','))\n",
    "                    test_list.append(np.loadtxt(tst_dir / f'{model}_test_pred_ver{i}.csv', delimiter=','))\n",
    "    \n",
    "    \n",
    "    return oof_list, test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['mlp_tfidf', 'mlp_hashing', 'mlp_bow','lr_tfidf','lr_hashing','lr_bow']\n",
    "\n",
    "# 의미없는 값\n",
    "number_of_ver = -1\n",
    "kind = 3\n",
    "\n",
    "all_oof, all_test = load_feature(model_names, number_of_ver, kind)\n",
    "all_oof = np.concatenate(all_oof, axis=1)\n",
    "all_test = np.concatenate(all_test, axis=1)\n",
    "all_oof.shape, all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54879,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(feature_target_file, index_col=0, usecols=['index',target_col]).values.flatten()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스태킹\n",
    "\n",
    "- 각 oof 마다 fold별로 logloos 변동이 있으므로 최대한 정보를 뽑아내고자 스태킹을 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 1000,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose' : 0,\n",
    "    'random_state': 2020\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(**rf_params)\n",
    "\n",
    "# Ada Boost Classifier parameters\n",
    "ada_params = {\n",
    "    'base_estimator': rf_clf,\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'algorithm': 'SAMME.R',\n",
    "    'random_state': 2020\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start : 1\n",
      "training model for CV #1\n",
      "[07:50:38] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.43528\tval-mlogloss:1.43988\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-mlogloss:0.28940\tval-mlogloss:0.42821\n",
      "\n",
      "training model for CV #2\n",
      "[07:50:45] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.43492\tval-mlogloss:1.44157\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[85]\ttrain-mlogloss:0.28447\tval-mlogloss:0.43038\n",
      "\n",
      "training model for CV #3\n",
      "[07:50:53] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.43556\tval-mlogloss:1.43885\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[101]\ttrain-mlogloss:0.26574\tval-mlogloss:0.41339\n",
      "\n",
      "training model for CV #4\n",
      "[07:51:01] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.43531\tval-mlogloss:1.44093\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[107]\ttrain-mlogloss:0.26027\tval-mlogloss:0.42698\n",
      "\n",
      "training model for CV #5\n",
      "[07:51:10] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.43519\tval-mlogloss:1.43836\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[88]\ttrain-mlogloss:0.27823\tval-mlogloss:0.42738\n",
      "\n",
      "end : 1\n"
     ]
    }
   ],
   "source": [
    "datasets = [(all_oof, all_test, y)]\n",
    "\n",
    "mlogloss = []\n",
    "\n",
    "ada_oof_preds = []\n",
    "ada_test_preds = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "for number, (X, test , y) in enumerate(datasets, 1):\n",
    "    print(f'start : {number}')\n",
    "    \n",
    "    ada_oof_pred = np.zeros((X.shape[0], n_class))\n",
    "    ada_test_pred = np.zeros((test.shape[0], n_class))\n",
    "    \n",
    "    for i, (i_trn, i_val) in enumerate(cv.split(X, y), 1):\n",
    "        print(f'training model for CV #{i}')\n",
    "        \n",
    "        X_train , X_val = X[i_trn], X[i_val]\n",
    "        y_train, y_val = y[i_trn], y[i_val]\n",
    "        \n",
    "        clf = AdaBoostClassifier(**ada_params)\n",
    "        clf.fit(X_train,y_train)\n",
    "                \n",
    "        ada_oof_pred[i_val, :] = clf.predict_proba(X_val)\n",
    "        ada_test_pred += clf.predict_proba(test) / n_fold\n",
    "        mlogloss.append(clf.best_score)\n",
    "    ada_oof_preds.append(ada_oof_pred)\n",
    "    ada_test_preds.append(ada_test_pred)\n",
    "    \n",
    "    print(f'end : {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss =   0.4271\n",
      "accuracy =  84.6590\n",
      "mean logloss =  0.4252668\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(ada_oof_preds,1):\n",
    "    print(f'logloss = {log_loss(pd.get_dummies(y),j):8.4f}')\n",
    "    print(f'accuracy = {accuracy_score(y, np.argmax(j,axis=1))*100:8.4f}')\n",
    "print('mean logloss = ',np.mean(mlogloss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 파일 및 기타 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 파일 생성\n",
    "\n",
    "sub = pd.read_csv(sample_file,index_col=0)\n",
    "sub[sub.columns] = ada_test_preds[0]\n",
    "sub.to_csv(stacking_submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking_oof_pred 파일 생성\n",
    "\n",
    "np.savetxt(stacking_oof_pred_file, ada_oof_preds[0],fmt='%.18f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking_test_pred 파일 생성\n",
    "\n",
    "np.savetxt(stacking_test_pred_file, ada_test_preds[0],fmt='%.18f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
