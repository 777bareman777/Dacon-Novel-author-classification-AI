{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:32:22.350713Z",
     "start_time": "2020-11-09T04:32:22.049823Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:32:23.188282Z",
     "start_time": "2020-11-09T04:32:22.352714Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:32:23.216883Z",
     "start_time": "2020-11-09T04:32:23.190555Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:32:23.250120Z",
     "start_time": "2020-11-09T04:32:23.219024Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path('../data/dacon-novel-author-classification')\n",
    "feature_dir = Path('../build/feature')\n",
    "val_dir = Path('../build/val')\n",
    "tst_dir = Path('../build/tst')\n",
    "sub_dir = Path('../build/sub')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:32:23.282083Z",
     "start_time": "2020-11-09T04:32:23.252439Z"
    }
   },
   "outputs": [],
   "source": [
    "algo_name = 'cnn'\n",
    "feature_name = 'tfidf-pca' #학습할 피처- tfidf 피처를 pca한 데이터\n",
    "feature_target = 'feature_target'\n",
    "\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv' #학습할 피처 가져오기\n",
    "feature_target_file = feature_dir / f'{feature_target}.csv' #target 데이터 가져오기\n",
    "\n",
    "p_val_ver7_file = val_dir / f'{model_name}_oof_pred_ver7.csv'\n",
    "p_tst_ver7_file = tst_dir / f'{model_name}_test_pred_ver7.csv'\n",
    "sub_ver7_file = sub_dir / f'{model_name}_ver7.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(feature_file, index_col=0)\n",
    "y = pd.read_csv(feature_target_file,index_col=0).values\n",
    "\n",
    "X_7 = X.iloc[:54879].values\n",
    "X_tst_7 = X.iloc[54879:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 500)\n",
      "(19617, 500)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_7.shape)\n",
    "print(X_tst_7.shape)\n",
    "print(type(X_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.60182778e-02,  1.35410949e-02, -6.60503286e-02, ...,\n",
       "         1.57118632e-02,  2.44125635e-02, -2.28590565e-02],\n",
       "       [ 1.74200713e-01, -8.09902055e-02,  6.68472899e-02, ...,\n",
       "        -5.03131627e-03,  1.66919764e-03,  5.90301730e-05],\n",
       "       [-1.08924886e-01,  6.13198590e-02, -4.60606378e-02, ...,\n",
       "        -9.58292290e-03,  6.45213673e-03,  2.15633840e-02],\n",
       "       ...,\n",
       "       [-1.19420009e-01, -1.24207603e-01,  2.51135526e-03, ...,\n",
       "         4.91452690e-03,  5.56308485e-03, -5.83548313e-04],\n",
       "       [ 2.62578871e-01, -1.01706863e-01,  8.66752065e-02, ...,\n",
       "        -4.21159256e-04,  3.75348681e-02,  1.00198717e-02],\n",
       "       [-6.30463041e-02,  2.93850081e-02, -4.86881601e-02, ...,\n",
       "        -3.69451299e-02,  8.40587639e-03, -5.72133739e-03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [2],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [3],\n",
       "       [0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:15:47.430701Z",
     "start_time": "2020-11-04T15:15:47.404265Z"
    }
   },
   "source": [
    "## cnn 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:45:10.370865Z",
     "start_time": "2020-11-09T04:45:10.344734Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(number):\n",
    "    inputs = Input(batch_shape=(None, number, 1))\n",
    "    x = Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(inputs)\n",
    "    x = Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(n_class, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:45:30.682036Z",
     "start_time": "2020-11-09T04:45:10.401772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for CV #1\n",
      "Epoch 1/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.3340 - val_loss: 1.1542\n",
      "Epoch 2/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.1089 - val_loss: 1.1094\n",
      "Epoch 3/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.0408 - val_loss: 1.0602\n",
      "Epoch 4/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9995 - val_loss: 1.0340\n",
      "Epoch 5/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9678 - val_loss: 1.0284\n",
      "Epoch 6/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9414 - val_loss: 1.0063\n",
      "Epoch 7/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9174 - val_loss: 1.0079\n",
      "Epoch 8/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9029 - val_loss: 1.0014\n",
      "Epoch 9/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8792 - val_loss: 1.0009\n",
      "Epoch 10/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8663 - val_loss: 1.0154\n",
      "Epoch 11/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8513 - val_loss: 1.0064\n",
      "Epoch 12/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8361 - val_loss: 0.9997\n",
      "Epoch 13/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8198 - val_loss: 1.0291\n",
      "Epoch 14/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8095 - val_loss: 1.0046\n",
      "Epoch 15/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7939 - val_loss: 1.0120\n",
      "Epoch 16/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7830 - val_loss: 0.9960\n",
      "Epoch 17/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7723 - val_loss: 1.0270\n",
      "Epoch 18/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7622 - val_loss: 1.0363\n",
      "Epoch 19/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7509 - val_loss: 1.0379\n",
      "Epoch 20/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7380 - val_loss: 1.0330\n",
      "Epoch 21/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7262 - val_loss: 1.0206\n",
      "Epoch 22/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7166 - val_loss: 1.0396\n",
      "Epoch 23/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7075 - val_loss: 1.0681\n",
      "Epoch 24/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.6962 - val_loss: 1.0418\n",
      "Epoch 25/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.6850 - val_loss: 1.1222\n",
      "Epoch 26/100\n",
      "680/686 [============================>.] - ETA: 0s - loss: 0.6724Restoring model weights from the end of the best epoch.\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.6722 - val_loss: 1.0950\n",
      "Epoch 00026: early stopping\n",
      "Training model for CV #2\n",
      "Epoch 1/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.3376 - val_loss: 1.1716\n",
      "Epoch 2/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.1094 - val_loss: 1.0896\n",
      "Epoch 3/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.0355 - val_loss: 1.0376\n",
      "Epoch 4/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9919 - val_loss: 1.0192\n",
      "Epoch 5/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9623 - val_loss: 1.0190\n",
      "Epoch 6/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9369 - val_loss: 1.0241\n",
      "Epoch 7/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9115 - val_loss: 0.9853\n",
      "Epoch 8/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8910 - val_loss: 0.9889\n",
      "Epoch 9/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8716 - val_loss: 0.9994\n",
      "Epoch 10/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8543 - val_loss: 0.9839\n",
      "Epoch 11/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8396 - val_loss: 0.9770\n",
      "Epoch 12/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8261 - val_loss: 0.9930\n",
      "Epoch 13/100\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.8095 - val_loss: 0.9835\n",
      "Epoch 14/100\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.7959 - val_loss: 0.9964\n",
      "Epoch 15/100\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.7856 - val_loss: 0.9913\n",
      "Epoch 16/100\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.7700 - val_loss: 0.9819\n",
      "Epoch 17/100\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.7556 - val_loss: 1.0175\n",
      "Epoch 18/100\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.7452 - val_loss: 1.0090\n",
      "Epoch 19/100\n",
      "686/686 [==============================] - 4s 5ms/step - loss: 0.7359 - val_loss: 1.0333\n",
      "Epoch 20/100\n",
      "686/686 [==============================] - 4s 5ms/step - loss: 0.7214 - val_loss: 1.0144\n",
      "Epoch 21/100\n",
      "684/686 [============================>.] - ETA: 0s - loss: 0.7102Restoring model weights from the end of the best epoch.\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.7100 - val_loss: 1.0289\n",
      "Epoch 00021: early stopping\n",
      "Training model for CV #3\n",
      "Epoch 1/100\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 1.3330 - val_loss: 1.1386\n",
      "Epoch 2/100\n",
      "686/686 [==============================] - 4s 5ms/step - loss: 1.1049 - val_loss: 1.0608\n",
      "Epoch 3/100\n",
      "686/686 [==============================] - 4s 5ms/step - loss: 1.0373 - val_loss: 1.0307\n",
      "Epoch 4/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9981 - val_loss: 1.0169\n",
      "Epoch 5/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9625 - val_loss: 1.0101\n",
      "Epoch 6/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.9377 - val_loss: 0.9895\n",
      "Epoch 7/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.9130 - val_loss: 0.9679\n",
      "Epoch 8/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8918 - val_loss: 0.9780\n",
      "Epoch 9/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8756 - val_loss: 0.9620\n",
      "Epoch 10/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8555 - val_loss: 0.9656\n",
      "Epoch 11/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8415 - val_loss: 0.9836\n",
      "Epoch 12/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8259 - val_loss: 0.9647\n",
      "Epoch 13/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8100 - val_loss: 0.9832\n",
      "Epoch 14/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7992 - val_loss: 0.9777\n",
      "Epoch 15/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7839 - val_loss: 0.9677\n",
      "Epoch 16/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7676 - val_loss: 0.9802\n",
      "Epoch 17/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7581 - val_loss: 0.9987\n",
      "Epoch 18/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7448 - val_loss: 1.0017\n",
      "Epoch 19/100\n",
      "686/686 [==============================] - ETA: 0s - loss: 0.7330Restoring model weights from the end of the best epoch.\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7330 - val_loss: 0.9984\n",
      "Epoch 00019: early stopping\n",
      "Training model for CV #4\n",
      "Epoch 1/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.3215 - val_loss: 1.1597\n",
      "Epoch 2/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.0891 - val_loss: 1.0938\n",
      "Epoch 3/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 1.0246 - val_loss: 1.0344\n",
      "Epoch 4/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9820 - val_loss: 1.0072\n",
      "Epoch 5/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9471 - val_loss: 1.0036\n",
      "Epoch 6/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9209 - val_loss: 1.0215\n",
      "Epoch 7/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.9007 - val_loss: 1.0076\n",
      "Epoch 8/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8794 - val_loss: 0.9745\n",
      "Epoch 9/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8548 - val_loss: 0.9827\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8382 - val_loss: 0.9724\n",
      "Epoch 11/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8209 - val_loss: 0.9982\n",
      "Epoch 12/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.8073 - val_loss: 0.9789\n",
      "Epoch 13/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7878 - val_loss: 0.9854\n",
      "Epoch 14/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7744 - val_loss: 0.9998\n",
      "Epoch 15/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7620 - val_loss: 1.0022\n",
      "Epoch 16/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7453 - val_loss: 1.0131\n",
      "Epoch 17/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7317 - val_loss: 1.0250\n",
      "Epoch 18/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7174 - val_loss: 1.0116\n",
      "Epoch 19/100\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.7043 - val_loss: 1.0076\n",
      "Epoch 20/100\n",
      "674/686 [============================>.] - ETA: 0s - loss: 0.6926Restoring model weights from the end of the best epoch.\n",
      "686/686 [==============================] - 3s 5ms/step - loss: 0.6938 - val_loss: 1.0161\n",
      "Epoch 00020: early stopping\n",
      "Training model for CV #5\n",
      "Epoch 1/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 1.3459 - val_loss: 1.1897\n",
      "Epoch 2/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 1.1164 - val_loss: 1.0795\n",
      "Epoch 3/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 1.0440 - val_loss: 1.0542\n",
      "Epoch 4/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.9981 - val_loss: 1.0327\n",
      "Epoch 5/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.9667 - val_loss: 1.0146\n",
      "Epoch 6/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.9406 - val_loss: 1.0009\n",
      "Epoch 7/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.9178 - val_loss: 0.9993\n",
      "Epoch 8/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8944 - val_loss: 1.0109\n",
      "Epoch 9/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8779 - val_loss: 1.0116\n",
      "Epoch 10/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8625 - val_loss: 0.9900\n",
      "Epoch 11/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8440 - val_loss: 1.0164\n",
      "Epoch 12/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8308 - val_loss: 1.0029\n",
      "Epoch 13/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8142 - val_loss: 1.0062\n",
      "Epoch 14/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.8016 - val_loss: 0.9982\n",
      "Epoch 15/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7864 - val_loss: 1.0466\n",
      "Epoch 16/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7784 - val_loss: 0.9964\n",
      "Epoch 17/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7642 - val_loss: 1.0208\n",
      "Epoch 18/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7552 - val_loss: 1.0170\n",
      "Epoch 19/100\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7393 - val_loss: 1.0296\n",
      "Epoch 20/100\n",
      "680/686 [============================>.] - ETA: 0s - loss: 0.7298Restoring model weights from the end of the best epoch.\n",
      "686/686 [==============================] - 3s 4ms/step - loss: 0.7300 - val_loss: 1.0478\n",
      "Epoch 00020: early stopping\n",
      "Training has finished\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "p_val_ver7 = np.zeros((X_7.shape[0], n_class))\n",
    "p_tst_ver7 = np.zeros((X_tst_7.shape[0], n_class))\n",
    "\n",
    "\n",
    "for X, test in [(X_7, X_tst_7)]:  \n",
    "    for i_cv, (i_trn, i_val) in enumerate(cv.split(X, y), 1):\n",
    "        print(f'Training model for CV #{i_cv}')\n",
    "        \n",
    "        es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "        \n",
    "        X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "        test = test.reshape(test.shape[0], test.shape[1],1)\n",
    "        \n",
    "        clf = get_model(X.shape[1])\n",
    "        clf.fit(X[i_trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=(X[i_val], to_categorical(y[i_val])),\n",
    "            epochs=100,\n",
    "            batch_size=64,\n",
    "            callbacks=[es])\n",
    "       \n",
    "        # Predict\n",
    "        if X.shape[1]==500:\n",
    "            p_val_ver7[i_val, :] = clf.predict(X[i_val])\n",
    "            p_tst_ver7 += clf.predict(test) / n_class\n",
    "        \n",
    "            \n",
    "        del clf\n",
    "        clear_session()\n",
    "        gc.collect()\n",
    "            \n",
    "    print(\"Training has finished\")\n",
    "    print(\"*\"*100)\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr ver7 Accuracy (CV):  62.3554%\n",
      "lr ver7 Log Loss (CV):   0.9798\n"
     ]
    }
   ],
   "source": [
    "print(f'lr ver7 Accuracy (CV): {accuracy_score(y, np.argmax(p_val_ver7, axis=1)) * 100:8.4f}%')\n",
    "print(f'lr ver7 Log Loss (CV): {log_loss(y, p_val_ver7):8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출 파일 생성 및 기타 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 파일 생성\n",
    "\n",
    "sub = pd.read_csv(sample_file, index_col=0)\n",
    "\n",
    "# Ver7\n",
    "sub[sub.columns] = p_tst_ver7\n",
    "sub.to_csv(sub_ver7_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T04:45:31.272596Z",
     "start_time": "2020-11-09T04:45:31.074976Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_val 파일 생성 -> oof\n",
    "\n",
    "# Ver7\n",
    "np.savetxt(p_val_ver7_file, p_val_ver7, fmt='%.18f', delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_tst 파일 생성 -> test \n",
    "\n",
    "# Ver7\n",
    "np.savetxt(p_tst_ver7_file, p_tst_ver7, fmt='%.18f', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
