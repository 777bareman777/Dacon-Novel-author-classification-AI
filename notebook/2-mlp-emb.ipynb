{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from matplotlib import rcParams, pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "# np.random.seed(seed)\n",
    "# rn.seed(seed)\n",
    "# tf.random.set_seed(seed)\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "#                              inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/dacon-novel-author-classification')\n",
    "feature_dir = Path('../build/feature')\n",
    "val_dir = Path('../build/val')\n",
    "tst_dir = Path('../build/tst')\n",
    "sub_dir = Path('../build/sub')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_name = 'mlp'\n",
    "feature_name = 'feature'\n",
    "model_name = f'{algorithm_name}_{feature_name}'\n",
    "\n",
    "feature_Ver1_file = feature_dir / f'{feature_name}_Ver1.csv'\n",
    "feature_Ver2_file = feature_dir / f'{feature_name}_Ver2.csv'\n",
    "feature_Ver3_file = feature_dir / f'{feature_name}_Ver3.csv'\n",
    "feature_Ver4_file = feature_dir / f'{feature_name}_Ver4.csv'\n",
    "\n",
    "\n",
    "mlp_oof_pred_ver1_file = val_dir / f'{model_name}_oof_pred_ver1.csv'\n",
    "mlp_oof_pred_ver2_file = val_dir / f'{model_name}_oof_pred_ver2.csv'\n",
    "mlp_oof_pred_ver3_file = val_dir / f'{model_name}_oof_pred_ver3.csv'\n",
    "mlp_oof_pred_ver4_file = val_dir / f'{model_name}_oof_pred_ver4.csv'\n",
    "\n",
    "\n",
    "mlp_test_pred_ver1_file = tst_dir / f'{model_name}_test_pred_ver1.csv'\n",
    "mlp_test_pred_ver2_file = tst_dir / f'{model_name}_test_pred_ver2.csv'\n",
    "mlp_test_pred_ver3_file = tst_dir / f'{model_name}_test_pred_ver3.csv'\n",
    "mlp_test_pred_ver4_file = tst_dir / f'{model_name}_test_pred_ver4.csv'\n",
    "\n",
    "\n",
    "mlp_submission_ver1_file = sub_dir / f'{model_name}_submission_Ver1.csv'\n",
    "mlp_submission_ver2_file = sub_dir / f'{model_name}_submission_Ver2.csv'\n",
    "mlp_submission_ver3_file = sub_dir / f'{model_name}_submission_Ver3.csv'\n",
    "mlp_submission_ver4_file = sub_dir / f'{model_name}_submission_Ver4.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver 1 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he was almost choking there was so much so muc...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your sister asked for it i suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she was engaged one day as she walked in peru...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the captain was in the porch keeping himself c...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have mercy gentlemen odin flung up his hands d...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      he was almost choking there was so much so muc...     3.0\n",
       "1                     your sister asked for it i suppose     2.0\n",
       "2       she was engaged one day as she walked in peru...     1.0\n",
       "3      the captain was in the porch keeping himself c...     4.0\n",
       "4      have mercy gentlemen odin flung up his hands d...     3.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver1_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver1_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver1_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver1_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver1_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver1_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver1_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver1_X.shape, Ver1_y.shape, Ver1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver 2 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost choking much much wanted say strange ex...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engaged one day walked perusing janes last let...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping carefully way treacherou...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mercy gentlemen odin flung hands dont write an...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      almost choking much much wanted say strange ex...     3.0\n",
       "1                                   sister asked suppose     2.0\n",
       "2      engaged one day walked perusing janes last let...     1.0\n",
       "3      captain porch keeping carefully way treacherou...     4.0\n",
       "4      mercy gentlemen odin flung hands dont write an...     3.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver2_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver2_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver2_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver2_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver2_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver2_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver2_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver2_X.shape, Ver2_y.shape, Ver2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver3 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost choking much much wanted say strange ex...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engaged day walked perusing janes last letter ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping himself carefully out wa...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mercy gentlemen flung up hands dont write anyw...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      almost choking much much wanted say strange ex...     3.0\n",
       "1                                   sister asked suppose     2.0\n",
       "2      engaged day walked perusing janes last letter ...     1.0\n",
       "3      captain porch keeping himself carefully out wa...     4.0\n",
       "4      mercy gentlemen flung up hands dont write anyw...     3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver3_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver3_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver3_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver3_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver3_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver3_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver3_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver3_X.shape, Ver3_y.shape, Ver3_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver4 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he almost choking there so much so much he wan...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked for it suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she engaged one day she walked perusing janes ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping himself carefully out wa...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have mercy gentlemen odin flung up hands dont ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      he almost choking there so much so much he wan...     3.0\n",
       "1                            sister asked for it suppose     2.0\n",
       "2      she engaged one day she walked perusing janes ...     1.0\n",
       "3      captain porch keeping himself carefully out wa...     4.0\n",
       "4      have mercy gentlemen odin flung up hands dont ...     3.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver4_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver4_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver4_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver4_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver4_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver4_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver4_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver4_X.shape, Ver4_y.shape, Ver4_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "vocab_size = 30000\n",
    "embedding_dim = 128\n",
    "max_length = 500\n",
    "padding_type='post'\n",
    "#oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=.0003))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start : 1\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 1.5828 - val_loss: 1.5682\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.5682 - val_loss: 1.5671\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5665 - val_loss: 1.5652\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5644 - val_loss: 1.5617\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5585 - val_loss: 1.5529\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5439 - val_loss: 1.5304\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5050 - val_loss: 1.4714\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.4290 - val_loss: 1.3842\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.3373 - val_loss: 1.2935\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.2508 - val_loss: 1.2207\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1820 - val_loss: 1.1698\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.1286 - val_loss: 1.1419\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.0901 - val_loss: 1.0955\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.0524 - val_loss: 1.0738\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0225 - val_loss: 1.0484\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9890 - val_loss: 1.0249\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9579 - val_loss: 1.0043\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9281 - val_loss: 0.9814\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8987 - val_loss: 0.9633\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8737 - val_loss: 0.9598\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8426 - val_loss: 0.9345\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8176 - val_loss: 0.9198\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.7921 - val_loss: 0.8988\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7689 - val_loss: 0.8972\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7486 - val_loss: 0.8756\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.7276 - val_loss: 0.8698\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7125 - val_loss: 0.8613\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6922 - val_loss: 0.8626\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.6706 - val_loss: 0.8444\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6576 - val_loss: 0.8568\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6375 - val_loss: 0.8367\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6215 - val_loss: 0.8330\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6077 - val_loss: 0.8314\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5929 - val_loss: 0.8323\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5825 - val_loss: 0.8251\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5698 - val_loss: 0.8230\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5541 - val_loss: 0.8240\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5420 - val_loss: 0.8370\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5331Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5331 - val_loss: 0.8363\n",
      "Epoch 00039: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 1.5810 - val_loss: 1.5690\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5682 - val_loss: 1.5678\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5668 - val_loss: 1.5664\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5648 - val_loss: 1.5635\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5596 - val_loss: 1.5564\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5466 - val_loss: 1.5375\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.5134 - val_loss: 1.4903\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4498 - val_loss: 1.4198\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3714 - val_loss: 1.3458\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2975 - val_loss: 1.2819\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2306 - val_loss: 1.2278\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1744 - val_loss: 1.1869\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1339 - val_loss: 1.1586\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0941 - val_loss: 1.1239\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0647 - val_loss: 1.1025\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0371 - val_loss: 1.0868\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0131 - val_loss: 1.0697\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9896 - val_loss: 1.0574\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9689 - val_loss: 1.0380\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9458 - val_loss: 1.0229\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9232 - val_loss: 1.0081\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8996 - val_loss: 0.9912\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8723 - val_loss: 0.9767\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8441 - val_loss: 0.9563\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8167 - val_loss: 0.9319\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7865 - val_loss: 0.9137\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7573 - val_loss: 0.8903\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7276 - val_loss: 0.8716\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6996 - val_loss: 0.8542\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6748 - val_loss: 0.8392\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6542 - val_loss: 0.8305\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6292 - val_loss: 0.8186\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6090 - val_loss: 0.8061\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5863 - val_loss: 0.8024\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5715 - val_loss: 0.7892\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5552 - val_loss: 0.7870\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5401 - val_loss: 0.7852\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5237 - val_loss: 0.7720\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5094 - val_loss: 0.7714\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4951 - val_loss: 0.7683\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4877 - val_loss: 0.7656\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4726 - val_loss: 0.7693\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4611 - val_loss: 0.7735\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4549Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4549 - val_loss: 0.7678\n",
      "Epoch 00044: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5814 - val_loss: 1.5682\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5679 - val_loss: 1.5667\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5662 - val_loss: 1.5642\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5621 - val_loss: 1.5584\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5526 - val_loss: 1.5458\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5284 - val_loss: 1.5068\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4756 - val_loss: 1.4380\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4096 - val_loss: 1.3830\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3524 - val_loss: 1.3339\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3068 - val_loss: 1.2940\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2654 - val_loss: 1.2585\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2232 - val_loss: 1.2223\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.1806 - val_loss: 1.1890\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1392 - val_loss: 1.1499\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1008 - val_loss: 1.1205\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.0724 - val_loss: 1.1044\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0419 - val_loss: 1.0763\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0167 - val_loss: 1.0638\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9946 - val_loss: 1.0535\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9764 - val_loss: 1.0296\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9552 - val_loss: 1.0294\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9331 - val_loss: 0.9994\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9105 - val_loss: 0.9853\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8836 - val_loss: 0.9643\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8589 - val_loss: 0.9492\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8306 - val_loss: 0.9253\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8031 - val_loss: 0.9185\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7794 - val_loss: 0.8886\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7529 - val_loss: 0.8748\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7267 - val_loss: 0.8583\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7033 - val_loss: 0.8494\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6835 - val_loss: 0.8504\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6635 - val_loss: 0.8359\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6492 - val_loss: 0.8155\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6233 - val_loss: 0.8300\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6071 - val_loss: 0.8067\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5882 - val_loss: 0.7976\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5756 - val_loss: 0.7988\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5573 - val_loss: 0.7916\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5427 - val_loss: 0.7873\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5316 - val_loss: 0.7819\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5193 - val_loss: 0.7827\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5046 - val_loss: 0.7904\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4956Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4956 - val_loss: 0.7867\n",
      "Epoch 00044: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5816 - val_loss: 1.5686\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5680 - val_loss: 1.5674\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5669 - val_loss: 1.5656\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5645 - val_loss: 1.5622\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5591 - val_loss: 1.5537\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5438 - val_loss: 1.5278\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5039 - val_loss: 1.4736\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4332 - val_loss: 1.3955\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3522 - val_loss: 1.3375\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2821 - val_loss: 1.2638\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2198 - val_loss: 1.2114\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1696 - val_loss: 1.1722\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1284 - val_loss: 1.1454\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0927 - val_loss: 1.1177\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0621 - val_loss: 1.0934\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0348 - val_loss: 1.0735\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0083 - val_loss: 1.0553\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9852 - val_loss: 1.0702\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9556 - val_loss: 1.0168\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9231 - val_loss: 0.9958\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8952 - val_loss: 0.9750\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8576 - val_loss: 0.9482\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8234 - val_loss: 0.9229\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7922 - val_loss: 0.9002\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7597 - val_loss: 0.8832\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7277 - val_loss: 0.8560\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6992 - val_loss: 0.8440\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6753 - val_loss: 0.8234\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6514 - val_loss: 0.8110\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6270 - val_loss: 0.7981\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6082 - val_loss: 0.7903\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5889 - val_loss: 0.7910\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5702 - val_loss: 0.7749\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5530 - val_loss: 0.7649\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5353 - val_loss: 0.7597\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5207 - val_loss: 0.7670\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5056 - val_loss: 0.7523\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4939 - val_loss: 0.7506\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4795 - val_loss: 0.7493\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4708 - val_loss: 0.7475\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4584 - val_loss: 0.7548\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.4469 - val_loss: 0.7448\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4378 - val_loss: 0.7453\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4336 - val_loss: 0.7521\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4208Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4208 - val_loss: 0.7490\n",
      "Epoch 00045: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 1.5861 - val_loss: 1.5686\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5682 - val_loss: 1.5675\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5670 - val_loss: 1.5662\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5653 - val_loss: 1.5636\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5613 - val_loss: 1.5568\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5502 - val_loss: 1.5410\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5236 - val_loss: 1.5004\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4695 - val_loss: 1.4338\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.3967 - val_loss: 1.3616\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3180 - val_loss: 1.2877\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2424 - val_loss: 1.2229\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1782 - val_loss: 1.1726\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1303 - val_loss: 1.1353\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0876 - val_loss: 1.1058\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0550 - val_loss: 1.0869\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0246 - val_loss: 1.0600\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9971 - val_loss: 1.0427\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9732 - val_loss: 1.0226\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9478 - val_loss: 1.0031\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9174 - val_loss: 0.9844\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8903 - val_loss: 0.9700\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8647 - val_loss: 0.9557\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8401 - val_loss: 0.9372\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8121 - val_loss: 0.9158\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7894 - val_loss: 0.9026\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7696 - val_loss: 0.8961\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7478 - val_loss: 0.8833\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7252 - val_loss: 0.8720\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7073 - val_loss: 0.8645\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6890 - val_loss: 0.8594\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6712 - val_loss: 0.8501\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6566 - val_loss: 0.8432\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6391 - val_loss: 0.8448\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6186 - val_loss: 0.8324\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6024 - val_loss: 0.8333\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5866 - val_loss: 0.8264\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5724 - val_loss: 0.8189\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5570 - val_loss: 0.8141\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5407 - val_loss: 0.8121\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5274 - val_loss: 0.8098\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5206 - val_loss: 0.8086\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5078 - val_loss: 0.8197\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.4958 - val_loss: 0.8132\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4805Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4805 - val_loss: 0.8156\n",
      "Epoch 00044: early stopping\n",
      "end : 1\n",
      "start : 2\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 1.5812 - val_loss: 1.5696\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5695 - val_loss: 1.5688\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5691 - val_loss: 1.5683\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5684 - val_loss: 1.5678\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5676 - val_loss: 1.5669\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5664 - val_loss: 1.5658\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5642 - val_loss: 1.5624\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5596 - val_loss: 1.5559\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5484 - val_loss: 1.5393\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5238 - val_loss: 1.5041\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.4728 - val_loss: 1.4407\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4051 - val_loss: 1.3724\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.3287 - val_loss: 1.3044\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2589 - val_loss: 1.2413\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.1958 - val_loss: 1.1847\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 1.1398 - val_loss: 1.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0962 - val_loss: 1.1141\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0646 - val_loss: 1.0908\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0322 - val_loss: 1.0705\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0053 - val_loss: 1.0528\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9842 - val_loss: 1.0387\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9611 - val_loss: 1.0362\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9396 - val_loss: 1.0163\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.9169 - val_loss: 1.0112\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8963 - val_loss: 0.9979\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8742 - val_loss: 0.9866\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8547 - val_loss: 0.9774\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8300 - val_loss: 0.9706\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8127 - val_loss: 0.9614\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.7865 - val_loss: 0.9421\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7632 - val_loss: 0.9292\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7389 - val_loss: 0.9166\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7136 - val_loss: 0.9183\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6932 - val_loss: 0.8853\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6663 - val_loss: 0.8761\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6436 - val_loss: 0.8622\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6270 - val_loss: 0.8489\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6026 - val_loss: 0.8431\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5821 - val_loss: 0.8328\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5670 - val_loss: 0.8260\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5526 - val_loss: 0.8285\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5380 - val_loss: 0.8144\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5233 - val_loss: 0.8192\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5096 - val_loss: 0.8072\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5007 - val_loss: 0.8076\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4867 - val_loss: 0.8091\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4787 - val_loss: 0.8054\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4663 - val_loss: 0.8074\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4610 - val_loss: 0.8043\n",
      "Epoch 50/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4490 - val_loss: 0.8016\n",
      "Epoch 51/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.4438 - val_loss: 0.8035\n",
      "Epoch 52/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.4364 - val_loss: 0.8133\n",
      "Epoch 53/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4261Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4261 - val_loss: 0.8026\n",
      "Epoch 00053: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5839 - val_loss: 1.5696\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5693 - val_loss: 1.5693\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5689 - val_loss: 1.5687\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5684 - val_loss: 1.5681\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5678 - val_loss: 1.5673\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5667 - val_loss: 1.5661\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5647 - val_loss: 1.5634\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5608 - val_loss: 1.5576\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5513 - val_loss: 1.5443\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5265 - val_loss: 1.5060\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4696 - val_loss: 1.4360\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.3752 - val_loss: 1.3346\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2760 - val_loss: 1.2546\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1963 - val_loss: 1.1945\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.1394 - val_loss: 1.1616\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0953 - val_loss: 1.1246\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0558 - val_loss: 1.0975\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0238 - val_loss: 1.0768\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9894 - val_loss: 1.0542\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9613 - val_loss: 1.0374\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9276 - val_loss: 1.0136\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8999 - val_loss: 1.0089\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.8759 - val_loss: 0.9925\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8503 - val_loss: 0.9714\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8245 - val_loss: 0.9476\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7980 - val_loss: 0.9348\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7748 - val_loss: 0.9258\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7522 - val_loss: 0.9104\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7299 - val_loss: 0.9006\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7071 - val_loss: 0.8886\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6870 - val_loss: 0.8789\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6681 - val_loss: 0.8704\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6455 - val_loss: 0.8698\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6279 - val_loss: 0.8551\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6136 - val_loss: 0.8622\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5966 - val_loss: 0.8406\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5756 - val_loss: 0.8335\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5651 - val_loss: 0.8277\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5483 - val_loss: 0.8305\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5373 - val_loss: 0.8255\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5219 - val_loss: 0.8179\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5114 - val_loss: 0.8301\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5004 - val_loss: 0.8202\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4894 - val_loss: 0.8136\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4843 - val_loss: 0.8140\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4687 - val_loss: 0.8141\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4606Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4606 - val_loss: 0.8176\n",
      "Epoch 00047: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5834 - val_loss: 1.5699\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5696 - val_loss: 1.5689\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5690 - val_loss: 1.5685\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5687 - val_loss: 1.5680\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5680 - val_loss: 1.5673\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5669 - val_loss: 1.5661\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5654 - val_loss: 1.5637\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5617 - val_loss: 1.5585\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5524 - val_loss: 1.5426\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5291 - val_loss: 1.5089\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4782 - val_loss: 1.4421\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4005 - val_loss: 1.3628\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3215 - val_loss: 1.2950\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2502 - val_loss: 1.2411\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.1887 - val_loss: 1.1789\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1355 - val_loss: 1.1415\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0937 - val_loss: 1.1115\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.0601 - val_loss: 1.0859\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0279 - val_loss: 1.0707\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0014 - val_loss: 1.0697\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9760 - val_loss: 1.0381\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9508 - val_loss: 1.0278\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9288 - val_loss: 1.0112\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9084 - val_loss: 1.0075\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8839 - val_loss: 0.9934\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8673 - val_loss: 0.9887\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8464 - val_loss: 0.9743\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8270 - val_loss: 0.9756\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8070 - val_loss: 0.9679\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7886 - val_loss: 0.9577\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7705 - val_loss: 0.9572\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7570 - val_loss: 0.9489\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7401 - val_loss: 0.9473\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7242 - val_loss: 0.9462\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7072 - val_loss: 0.9420\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6930 - val_loss: 0.9431\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6778 - val_loss: 0.9395\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6677 - val_loss: 0.9419\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6514 - val_loss: 0.9386\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6394Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6394 - val_loss: 0.9390\n",
      "Epoch 00040: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5831 - val_loss: 1.5697\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5696 - val_loss: 1.5689\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5691 - val_loss: 1.5687\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5686 - val_loss: 1.5681\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5677 - val_loss: 1.5673\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5669 - val_loss: 1.5658\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5647 - val_loss: 1.5630\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5599 - val_loss: 1.5559\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5472 - val_loss: 1.5372\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5175 - val_loss: 1.4995\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4727 - val_loss: 1.4548\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4280 - val_loss: 1.4173\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3879 - val_loss: 1.3826\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3447 - val_loss: 1.3405\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2876 - val_loss: 1.2843\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2220 - val_loss: 1.2239\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1522 - val_loss: 1.1685\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0915 - val_loss: 1.1226\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0412 - val_loss: 1.0893\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9972 - val_loss: 1.0591\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9586 - val_loss: 1.0367\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9250 - val_loss: 1.0161\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8948 - val_loss: 1.0063\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.8715 - val_loss: 0.9853\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8438 - val_loss: 0.9688\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8192 - val_loss: 0.9591\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7977 - val_loss: 0.9467\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7760 - val_loss: 0.9403\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.7584 - val_loss: 0.9364\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7448 - val_loss: 0.9218\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7251 - val_loss: 0.9393\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7075 - val_loss: 0.9087\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6885 - val_loss: 0.9057\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6736 - val_loss: 0.9101\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6593 - val_loss: 0.8999\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6449 - val_loss: 0.8944\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6341 - val_loss: 0.9047\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6226 - val_loss: 0.8921\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6054 - val_loss: 0.8925\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5979 - val_loss: 0.8940\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5826Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5826 - val_loss: 0.8969\n",
      "Epoch 00041: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5871 - val_loss: 1.5697\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5696 - val_loss: 1.5690\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5690 - val_loss: 1.5689\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5684 - val_loss: 1.5680\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5678 - val_loss: 1.5674\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5669 - val_loss: 1.5662\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5651 - val_loss: 1.5635\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5615 - val_loss: 1.5583\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5513 - val_loss: 1.5436\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5240 - val_loss: 1.5014\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4668 - val_loss: 1.4361\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3823 - val_loss: 1.3426\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.2826 - val_loss: 1.2542\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1949 - val_loss: 1.1881\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.1305 - val_loss: 1.1436\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0792 - val_loss: 1.1031\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0373 - val_loss: 1.0752\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9993 - val_loss: 1.0395\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9613 - val_loss: 1.0147\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9256 - val_loss: 0.9940\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8942 - val_loss: 0.9731\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.8633 - val_loss: 0.9553\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.8353 - val_loss: 0.9390\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8059 - val_loss: 0.9255\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7816 - val_loss: 0.9130\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7577 - val_loss: 0.9010\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7358 - val_loss: 0.8899\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7134 - val_loss: 0.8795\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6934 - val_loss: 0.8730\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6725 - val_loss: 0.8647\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 111ms/step - loss: 0.6560 - val_loss: 0.8664\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6384 - val_loss: 0.8597\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6218 - val_loss: 0.8466\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6044 - val_loss: 0.8422\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5915 - val_loss: 0.8375\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5733 - val_loss: 0.8341\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5596 - val_loss: 0.8306\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5467 - val_loss: 0.8285\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5329 - val_loss: 0.8270\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5251 - val_loss: 0.8370\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5148 - val_loss: 0.8253\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5016 - val_loss: 0.8241\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4939 - val_loss: 0.8218\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4830 - val_loss: 0.8215\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4731 - val_loss: 0.8227\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4655Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4655 - val_loss: 0.8416\n",
      "Epoch 00046: early stopping\n",
      "end : 2\n",
      "start : 3\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.5841 - val_loss: 1.5694\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5695 - val_loss: 1.5689\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5691 - val_loss: 1.5686\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5687 - val_loss: 1.5682\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5683 - val_loss: 1.5677\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5676 - val_loss: 1.5666\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5661 - val_loss: 1.5648\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5633 - val_loss: 1.5611\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5571 - val_loss: 1.5514\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5415 - val_loss: 1.5297\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5041 - val_loss: 1.4803\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4391 - val_loss: 1.4109\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3663 - val_loss: 1.3414\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3033 - val_loss: 1.2869\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.2493 - val_loss: 1.2380\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1968 - val_loss: 1.1971\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1534 - val_loss: 1.1660\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1145 - val_loss: 1.1305\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0807 - val_loss: 1.1155\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0530 - val_loss: 1.0864\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0214 - val_loss: 1.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9978 - val_loss: 1.0579\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.9708 - val_loss: 1.0348\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9428 - val_loss: 1.0171\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.9197 - val_loss: 1.0070\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8950 - val_loss: 0.9870\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8692 - val_loss: 0.9674\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.8383 - val_loss: 0.9527\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8131 - val_loss: 0.9340\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7821 - val_loss: 0.9117\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7550 - val_loss: 0.8931\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7288 - val_loss: 0.8769\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7003 - val_loss: 0.8640\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6732 - val_loss: 0.8498\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6533 - val_loss: 0.8421\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6318 - val_loss: 0.8252\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6094 - val_loss: 0.8159\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5928 - val_loss: 0.8083\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5783 - val_loss: 0.8031\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5629 - val_loss: 0.8014\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5488 - val_loss: 0.7993\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5367 - val_loss: 0.7937\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5237 - val_loss: 0.7956\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5084 - val_loss: 0.7856\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4991 - val_loss: 0.7835\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.4899 - val_loss: 0.7822\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.4787 - val_loss: 0.7917\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.4709 - val_loss: 0.7847\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4590Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4590 - val_loss: 0.7955\n",
      "Epoch 00049: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 1.5808 - val_loss: 1.5703\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5694 - val_loss: 1.5694\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5689 - val_loss: 1.5688\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5686 - val_loss: 1.5688\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5678 - val_loss: 1.5676\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5668 - val_loss: 1.5663\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5651 - val_loss: 1.5642\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5612 - val_loss: 1.5588\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5517 - val_loss: 1.5439\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5246 - val_loss: 1.5031\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4585 - val_loss: 1.4160\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3544 - val_loss: 1.3195\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2572 - val_loss: 1.2332\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.1760 - val_loss: 1.1720\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1111 - val_loss: 1.1243\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0600 - val_loss: 1.0903\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0122 - val_loss: 1.0532\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9713 - val_loss: 1.0276\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9361 - val_loss: 1.0047\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9016 - val_loss: 0.9880\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8762 - val_loss: 0.9704\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8445 - val_loss: 0.9578\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8211 - val_loss: 0.9425\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7970 - val_loss: 0.9304\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7782 - val_loss: 0.9216\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7542 - val_loss: 0.9185\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7373 - val_loss: 0.9118\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7174 - val_loss: 0.9240\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6996 - val_loss: 0.9043\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6917 - val_loss: 0.8928\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6663 - val_loss: 0.8975\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6529 - val_loss: 0.8874\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6394 - val_loss: 0.8841\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6269 - val_loss: 0.8841\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6158 - val_loss: 0.8825\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6010 - val_loss: 0.8846\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5937 - val_loss: 0.8961\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5912Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5912 - val_loss: 0.8864\n",
      "Epoch 00038: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.5839 - val_loss: 1.5698\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5695 - val_loss: 1.5690\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5691 - val_loss: 1.5685\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5685 - val_loss: 1.5679\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5677 - val_loss: 1.5670\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5666 - val_loss: 1.5654\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5646 - val_loss: 1.5625\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5601 - val_loss: 1.5562\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5498 - val_loss: 1.5399\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5213 - val_loss: 1.4996\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4582 - val_loss: 1.4223\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3738 - val_loss: 1.3389\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3035 - val_loss: 1.2849\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2512 - val_loss: 1.2439\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2051 - val_loss: 1.2059\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.1616 - val_loss: 1.1685\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1208 - val_loss: 1.1379\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0855 - val_loss: 1.1246\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.0507 - val_loss: 1.0846\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0204 - val_loss: 1.0653\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9920 - val_loss: 1.0490\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9672 - val_loss: 1.0371\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9416 - val_loss: 1.0196\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9201 - val_loss: 1.0086\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8960 - val_loss: 0.9975\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8776 - val_loss: 0.9875\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8583 - val_loss: 0.9818\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8445 - val_loss: 0.9784\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8278 - val_loss: 0.9698\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8115 - val_loss: 0.9633\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7975 - val_loss: 0.9605\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7854 - val_loss: 0.9667\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7732 - val_loss: 0.9605\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7614 - val_loss: 0.9530\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7494 - val_loss: 0.9536\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7413 - val_loss: 0.9553\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7294 - val_loss: 0.9500\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7177 - val_loss: 0.9494\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7069 - val_loss: 0.9477\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6957 - val_loss: 0.9609\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6878 - val_loss: 0.9580\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6785Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6785 - val_loss: 0.9540\n",
      "Epoch 00042: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5832 - val_loss: 1.5698\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5694 - val_loss: 1.5691\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5689 - val_loss: 1.5686\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5685 - val_loss: 1.5681\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5679 - val_loss: 1.5674\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5669 - val_loss: 1.5663\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5655 - val_loss: 1.5643\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5620 - val_loss: 1.5596\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5548 - val_loss: 1.5487\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5363 - val_loss: 1.5209\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4900 - val_loss: 1.4587\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4114 - val_loss: 1.3812\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3391 - val_loss: 1.3244\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.2823 - val_loss: 1.2838\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2312 - val_loss: 1.2385\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.1891 - val_loss: 1.2067\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1449 - val_loss: 1.1835\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1059 - val_loss: 1.1443\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0701 - val_loss: 1.1168\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.0335 - val_loss: 1.0936\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0018 - val_loss: 1.0695\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9702 - val_loss: 1.0512\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9420 - val_loss: 1.0299\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.9097 - val_loss: 1.0115\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8809 - val_loss: 0.9926\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8534 - val_loss: 0.9755\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8251 - val_loss: 0.9596\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7950 - val_loss: 0.9417\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7693 - val_loss: 0.9293\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7442 - val_loss: 0.9098\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7194 - val_loss: 0.8980\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6924 - val_loss: 0.8863\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6732 - val_loss: 0.8787\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6494 - val_loss: 0.8603\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6292 - val_loss: 0.8577\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6119 - val_loss: 0.8522\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6003 - val_loss: 0.8551\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5800 - val_loss: 0.8293\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5634 - val_loss: 0.8315\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5532 - val_loss: 0.8258\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5376 - val_loss: 0.8176\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5256 - val_loss: 0.8249\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5147 - val_loss: 0.8232\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5035Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5035 - val_loss: 0.8169\n",
      "Epoch 00044: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5828 - val_loss: 1.5697\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5692 - val_loss: 1.5690\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5691 - val_loss: 1.5687\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5684 - val_loss: 1.5680\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5677 - val_loss: 1.5668\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5659 - val_loss: 1.5649\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5628 - val_loss: 1.5605\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5544 - val_loss: 1.5474\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5332 - val_loss: 1.5166\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4862 - val_loss: 1.4572\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.4169 - val_loss: 1.3919\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3545 - val_loss: 1.3462\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3131 - val_loss: 1.3072\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2741 - val_loss: 1.2805\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.2418 - val_loss: 1.2550\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2129 - val_loss: 1.2416\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1869 - val_loss: 1.2064\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1572 - val_loss: 1.1832\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1304 - val_loss: 1.1726\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1058 - val_loss: 1.1455\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0862 - val_loss: 1.1278\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0612 - val_loss: 1.1145\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0412 - val_loss: 1.1014\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.0240 - val_loss: 1.0900\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0053 - val_loss: 1.0821\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9930 - val_loss: 1.0772\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9798 - val_loss: 1.0622\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.9579 - val_loss: 1.0527\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9428 - val_loss: 1.0444\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9238 - val_loss: 1.0378\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9110 - val_loss: 1.0250\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8913 - val_loss: 1.0333\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8734 - val_loss: 1.0187\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.8565 - val_loss: 0.9991\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8372 - val_loss: 1.0063\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8194 - val_loss: 0.9859\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8024 - val_loss: 0.9760\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7858 - val_loss: 0.9685\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7683 - val_loss: 0.9659\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7606 - val_loss: 0.9602\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7375 - val_loss: 0.9534\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7201 - val_loss: 0.9505\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7052 - val_loss: 0.9417\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6896 - val_loss: 0.9326\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6765 - val_loss: 0.9404\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6621 - val_loss: 0.9302\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6472 - val_loss: 0.9198\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.6347 - val_loss: 0.9210\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6250 - val_loss: 0.9264\n",
      "Epoch 50/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6107Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6107 - val_loss: 0.9202\n",
      "Epoch 00050: early stopping\n",
      "end : 3\n",
      "start : 4\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5809 - val_loss: 1.5690\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5687 - val_loss: 1.5678\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5675 - val_loss: 1.5665\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 1.5656 - val_loss: 1.5636\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5611 - val_loss: 1.5569\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5503 - val_loss: 1.5403\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5227 - val_loss: 1.4994\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4623 - val_loss: 1.4212\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3739 - val_loss: 1.3305\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2874 - val_loss: 1.2617\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.2201 - val_loss: 1.2043\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1658 - val_loss: 1.1599\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1229 - val_loss: 1.1320\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0843 - val_loss: 1.1020\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.0512 - val_loss: 1.0748\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0187 - val_loss: 1.0562\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9910 - val_loss: 1.0383\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9594 - val_loss: 1.0115\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9292 - val_loss: 0.9937\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9036 - val_loss: 0.9820\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8740 - val_loss: 0.9530\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8478 - val_loss: 0.9418\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.8258 - val_loss: 0.9252\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8005 - val_loss: 0.9098\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7814 - val_loss: 0.8986\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7588 - val_loss: 0.8939\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7424 - val_loss: 0.8876\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7223 - val_loss: 0.8730\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7033 - val_loss: 0.8648\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6884 - val_loss: 0.8614\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6682 - val_loss: 0.8521\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6533 - val_loss: 0.8571\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6411 - val_loss: 0.8465\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6218 - val_loss: 0.8434\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6094 - val_loss: 0.8359\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5947 - val_loss: 0.8377\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5845 - val_loss: 0.8331\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5707 - val_loss: 0.8563\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5645 - val_loss: 0.8350\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5467Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5467 - val_loss: 0.8326\n",
      "Epoch 00040: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5820 - val_loss: 1.5693\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5686 - val_loss: 1.5684\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5679 - val_loss: 1.5674\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5664 - val_loss: 1.5658\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5639 - val_loss: 1.5618\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5566 - val_loss: 1.5508\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5394 - val_loss: 1.5289\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5072 - val_loss: 1.4974\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4577 - val_loss: 1.4435\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3994 - val_loss: 1.3835\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3427 - val_loss: 1.3325\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2870 - val_loss: 1.2827\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2322 - val_loss: 1.2373\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1821 - val_loss: 1.1949\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1369 - val_loss: 1.1615\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1039 - val_loss: 1.1381\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.0711 - val_loss: 1.1106\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0433 - val_loss: 1.0947\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0199 - val_loss: 1.0789\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9996 - val_loss: 1.0668\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.9811 - val_loss: 1.0596\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9633 - val_loss: 1.0485\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9480 - val_loss: 1.0361\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9263 - val_loss: 1.0222\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9070 - val_loss: 1.0086\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8851 - val_loss: 0.9956\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8622 - val_loss: 0.9829\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8356 - val_loss: 0.9573\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8070 - val_loss: 0.9428\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7827 - val_loss: 0.9240\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7536 - val_loss: 0.9071\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7322 - val_loss: 0.8984\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7065 - val_loss: 0.8699\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6832 - val_loss: 0.8552\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6604 - val_loss: 0.8429\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6384 - val_loss: 0.8311\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6198 - val_loss: 0.8209\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6027 - val_loss: 0.8169\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5848 - val_loss: 0.8068\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5661 - val_loss: 0.7976\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5502 - val_loss: 0.7891\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5336 - val_loss: 0.7878\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5193 - val_loss: 0.7893\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5082 - val_loss: 0.7754\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4986 - val_loss: 0.7757\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4812 - val_loss: 0.7697\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.4740 - val_loss: 0.7715\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4610 - val_loss: 0.7773\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4499Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4499 - val_loss: 0.7783\n",
      "Epoch 00049: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 1.5827 - val_loss: 1.5691\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5684 - val_loss: 1.5676\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5674 - val_loss: 1.5662\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5651 - val_loss: 1.5627\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5600 - val_loss: 1.5554\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.5487 - val_loss: 1.5383\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5234 - val_loss: 1.5030\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4781 - val_loss: 1.4497\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4224 - val_loss: 1.3930\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.3621 - val_loss: 1.3388\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3027 - val_loss: 1.2831\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.2417 - val_loss: 1.2268\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1832 - val_loss: 1.1777\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1313 - val_loss: 1.1354\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0834 - val_loss: 1.1001\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0410 - val_loss: 1.0700\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0023 - val_loss: 1.0446\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9635 - val_loss: 1.0299\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 114ms/step - loss: 0.9407 - val_loss: 0.9969\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.8992 - val_loss: 0.9813\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8678 - val_loss: 0.9558\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8381 - val_loss: 0.9393\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8099 - val_loss: 0.9269\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7830 - val_loss: 0.9087\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7576 - val_loss: 0.8948\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7366 - val_loss: 0.8857\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.7092 - val_loss: 0.8732\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6853 - val_loss: 0.8607\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6633 - val_loss: 0.8516\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6457 - val_loss: 0.8427\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6235 - val_loss: 0.8353\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.6065 - val_loss: 0.8254\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5892 - val_loss: 0.8202\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5720 - val_loss: 0.8193\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5580 - val_loss: 0.8231\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5441 - val_loss: 0.8120\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5305 - val_loss: 0.8068\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.5158 - val_loss: 0.8010\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5024 - val_loss: 0.8001\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4937 - val_loss: 0.8043\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4890Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4890 - val_loss: 0.8040\n",
      "Epoch 00041: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 1.5818 - val_loss: 1.5693\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5686 - val_loss: 1.5682\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5678 - val_loss: 1.5672\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5663 - val_loss: 1.5654\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5637 - val_loss: 1.5608\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5554 - val_loss: 1.5478\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5337 - val_loss: 1.5162\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.4862 - val_loss: 1.4519\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4084 - val_loss: 1.3664\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.3161 - val_loss: 1.2783\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.2327 - val_loss: 1.2142\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1687 - val_loss: 1.1649\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.1210 - val_loss: 1.1260\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0850 - val_loss: 1.1014\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.0549 - val_loss: 1.0855\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.0270 - val_loss: 1.0625\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0028 - val_loss: 1.0459\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9811 - val_loss: 1.0268\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9561 - val_loss: 1.0144\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9337 - val_loss: 1.0017\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9094 - val_loss: 0.9840\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8825 - val_loss: 0.9648\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8578 - val_loss: 0.9533\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8328 - val_loss: 0.9378\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.8110 - val_loss: 0.9256\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7852 - val_loss: 0.9157\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7682 - val_loss: 0.9074\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7439 - val_loss: 0.8922\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7259 - val_loss: 0.8822\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7045 - val_loss: 0.8898\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6839 - val_loss: 0.8729\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6659 - val_loss: 0.8679\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6488 - val_loss: 0.8600\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6312 - val_loss: 0.8488\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6107 - val_loss: 0.8399\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5963 - val_loss: 0.8357\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5779 - val_loss: 0.8296\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5649 - val_loss: 0.8393\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5558 - val_loss: 0.8275\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5390 - val_loss: 0.8221\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5233 - val_loss: 0.8178\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5123 - val_loss: 0.8188\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5057 - val_loss: 0.8245\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4903Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4903 - val_loss: 0.8213\n",
      "Epoch 00044: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 1.5795 - val_loss: 1.5690\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5686 - val_loss: 1.5680\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5678 - val_loss: 1.5672\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5664 - val_loss: 1.5652\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5635 - val_loss: 1.5607\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.5556 - val_loss: 1.5485\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.5365 - val_loss: 1.5201\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.4958 - val_loss: 1.4673\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.4265 - val_loss: 1.3852\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.3347 - val_loss: 1.2976\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.2479 - val_loss: 1.2260\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1789 - val_loss: 1.1734\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 1.1271 - val_loss: 1.1386\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 1.0875 - val_loss: 1.1087\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0535 - val_loss: 1.0864\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 1.0253 - val_loss: 1.0685\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9962 - val_loss: 1.0483\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9706 - val_loss: 1.0331\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9438 - val_loss: 1.0186\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.9131 - val_loss: 0.9932\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8845 - val_loss: 0.9816\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8546 - val_loss: 0.9534\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.8230 - val_loss: 0.9368\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.7944 - val_loss: 0.9173\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7674 - val_loss: 0.9054\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.7388 - val_loss: 0.8892\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.7123 - val_loss: 0.8673\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6887 - val_loss: 0.8547\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6641 - val_loss: 0.8405\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.6424 - val_loss: 0.8294\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.6187 - val_loss: 0.8204\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.5996 - val_loss: 0.8166\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5839 - val_loss: 0.8078\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5631 - val_loss: 0.8094\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5482 - val_loss: 0.7947\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5321 - val_loss: 0.7897\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.5210 - val_loss: 0.8058\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.5082 - val_loss: 0.7892\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.4933 - val_loss: 0.7859\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4806 - val_loss: 0.8008\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4722 - val_loss: 0.7829\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4620 - val_loss: 0.7940\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.4494 - val_loss: 0.7855\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4444Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.4444 - val_loss: 0.7866\n",
      "Epoch 00044: early stopping\n",
      "end : 4\n"
     ]
    }
   ],
   "source": [
    "datasets = [ (Ver1_X, Ver1_test, Ver1_y), (Ver2_X, Ver2_test, Ver2_y),\n",
    "            (Ver3_X, Ver3_test, Ver3_y), (Ver4_X, Ver4_test, Ver3_y)]\n",
    "\n",
    "mlp_oof_preds = []\n",
    "mlp_test_preds = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "for number ,(X, test, y) in enumerate(datasets,1):\n",
    "    print(f'start : {number}')\n",
    "    # 토큰화\n",
    "    X_train = np.array([x for x in X['text']])\n",
    "    X_test = np.array([x for x in test['text']])\n",
    "    y = np.array(y.values)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words = vocab_size)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # 시퀸스화 + 패딩\n",
    "    train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "    tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
    "    print(trn.shape, tst.shape)\n",
    "    \n",
    "    # oof , test 저장\n",
    "    mlp_oof_pred = np.zeros((trn.shape[0], n_class))\n",
    "    mlp_test_pred = np.zeros((tst.shape[0], n_class))\n",
    "    \n",
    "    for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "        print(f'traing model for CV #{i}')\n",
    "        clf = get_model()\n",
    "        \n",
    "        es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "        \n",
    "        clf.fit(trn[i_trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
    "            epochs=200,\n",
    "            batch_size=1024,\n",
    "            callbacks=[es])\n",
    "        \n",
    "        mlp_oof_pred[i_val, :] = clf.predict(trn[i_val])\n",
    "        mlp_test_pred += clf.predict(tst) / n_fold\n",
    "        \n",
    "        del clf\n",
    "        clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    mlp_oof_preds.append(mlp_oof_pred)\n",
    "    mlp_test_preds.append(mlp_test_pred)\n",
    "        \n",
    "    print(f'end : {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver1 logloss =   0.7848\n",
      "ver1 logloss =  71.0909\n",
      "ver2 logloss =   0.8537\n",
      "ver2 logloss =  68.8661\n",
      "ver3 logloss =   0.8700\n",
      "ver3 logloss =  67.3828\n",
      "ver4 logloss =   0.8009\n",
      "ver4 logloss =  70.7885\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(mlp_oof_preds,1):\n",
    "    print(f'ver{i} logloss = {log_loss(pd.get_dummies(y),j):8.4f}')\n",
    "    print(f'ver{i} accuracy = {accuracy_score(y, np.argmax(j,axis=1))*100:8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 파일 및 기타 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 파일 생성\n",
    "\n",
    "sub = pd.read_csv(sample_file,index_col=0)\n",
    "\n",
    "# Ver1 \n",
    "sub[sub.columns] = mlp_test_preds[0]\n",
    "sub.to_csv(mlp_submission_ver1_file)\n",
    "\n",
    "# Ver2\n",
    "sub[sub.columns] = mlp_test_preds[1]\n",
    "sub.to_csv(mlp_submission_ver2_file)\n",
    "\n",
    "# Ver3\n",
    "sub[sub.columns] = mlp_test_preds[2]\n",
    "sub.to_csv(mlp_submission_ver3_file)\n",
    "           \n",
    "# Ver4\n",
    "sub[sub.columns] = mlp_test_preds[3]\n",
    "sub.to_csv(mlp_submission_ver4_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_oof_pred 파일 생성\n",
    "\n",
    "# Ver1\n",
    "np.savetxt(mlp_oof_pred_ver1_file, mlp_oof_preds[0],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver2\n",
    "np.savetxt(mlp_oof_pred_ver2_file, mlp_oof_preds[1],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver3\n",
    "np.savetxt(mlp_oof_pred_ver3_file, mlp_oof_preds[2],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver4\n",
    "np.savetxt(mlp_oof_pred_ver4_file, mlp_oof_preds[3],fmt='%.18f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_test_pred 파일 생성\n",
    "\n",
    "# Ver1\n",
    "np.savetxt(mlp_test_pred_ver1_file, mlp_test_preds[0],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver2\n",
    "np.savetxt(mlp_test_pred_ver2_file, mlp_test_preds[1],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver3\n",
    "np.savetxt(mlp_test_pred_ver3_file, mlp_test_preds[2],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver4\n",
    "np.savetxt(mlp_test_pred_ver4_file, mlp_test_preds[3],fmt='%.18f', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
