{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from matplotlib import rcParams, pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "# np.random.seed(seed)\n",
    "# rn.seed(seed)\n",
    "# tf.random.set_seed(seed)\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "#                              inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/dacon-novel-author-classification')\n",
    "feature_dir = Path('../build/feature')\n",
    "val_dir = Path('../build/val')\n",
    "tst_dir = Path('../build/tst')\n",
    "sub_dir = Path('../build/sub')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_name = 'lstm'\n",
    "feature_name = 'feature'\n",
    "model_name = f'{algorithm_name}_{feature_name}'\n",
    "\n",
    "feature_Ver1_file = feature_dir / f'{feature_name}_Ver1.csv'\n",
    "feature_Ver2_file = feature_dir / f'{feature_name}_Ver2.csv'\n",
    "feature_Ver3_file = feature_dir / f'{feature_name}_Ver3.csv'\n",
    "feature_Ver4_file = feature_dir / f'{feature_name}_Ver4.csv'\n",
    "\n",
    "\n",
    "lstm_oof_pred_ver1_file = val_dir / f'{model_name}_oof_pred_ver1.csv'\n",
    "lstm_oof_pred_ver2_file = val_dir / f'{model_name}_oof_pred_ver2.csv'\n",
    "lstm_oof_pred_ver3_file = val_dir / f'{model_name}_oof_pred_ver3.csv'\n",
    "lstm_oof_pred_ver4_file = val_dir / f'{model_name}_oof_pred_ver4.csv'\n",
    "\n",
    "\n",
    "lstm_test_pred_ver1_file = tst_dir / f'{model_name}_test_pred_ver1.csv'\n",
    "lstm_test_pred_ver2_file = tst_dir / f'{model_name}_test_pred_ver2.csv'\n",
    "lstm_test_pred_ver3_file = tst_dir / f'{model_name}_test_pred_ver3.csv'\n",
    "lstm_test_pred_ver4_file = tst_dir / f'{model_name}_test_pred_ver4.csv'\n",
    "\n",
    "\n",
    "lstm_submission_ver1_file = sub_dir / f'{model_name}_submission_Ver1.csv'\n",
    "lstm_submission_ver2_file = sub_dir / f'{model_name}_submission_Ver2.csv'\n",
    "lstm_submission_ver3_file = sub_dir / f'{model_name}_submission_Ver3.csv'\n",
    "lstm_submission_ver4_file = sub_dir / f'{model_name}_submission_Ver4.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver 1 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he was almost choking there was so much so muc...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your sister asked for it i suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she was engaged one day as she walked in peru...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the captain was in the porch keeping himself c...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have mercy gentlemen odin flung up his hands d...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      he was almost choking there was so much so muc...     3.0\n",
       "1                     your sister asked for it i suppose     2.0\n",
       "2       she was engaged one day as she walked in peru...     1.0\n",
       "3      the captain was in the porch keeping himself c...     4.0\n",
       "4      have mercy gentlemen odin flung up his hands d...     3.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver1_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver1_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver1_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver1_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver1_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver1_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver1_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver1_X.shape, Ver1_y.shape, Ver1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver 2 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost choking much much wanted say strange ex...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engaged one day walked perusing janes last let...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping carefully way treacherou...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mercy gentlemen odin flung hands dont write an...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      almost choking much much wanted say strange ex...     3.0\n",
       "1                                   sister asked suppose     2.0\n",
       "2      engaged one day walked perusing janes last let...     1.0\n",
       "3      captain porch keeping carefully way treacherou...     4.0\n",
       "4      mercy gentlemen odin flung hands dont write an...     3.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver2_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver2_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver2_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver2_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver2_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver2_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver2_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver2_X.shape, Ver2_y.shape, Ver2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver3 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost choking much much wanted say strange ex...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engaged day walked perusing janes last letter ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping himself carefully out wa...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mercy gentlemen flung up hands dont write anyw...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      almost choking much much wanted say strange ex...     3.0\n",
       "1                                   sister asked suppose     2.0\n",
       "2      engaged day walked perusing janes last letter ...     1.0\n",
       "3      captain porch keeping himself carefully out wa...     4.0\n",
       "4      mercy gentlemen flung up hands dont write anyw...     3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver3_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver3_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver3_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver3_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver3_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver3_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver3_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver3_X.shape, Ver3_y.shape, Ver3_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver4 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he almost choking there so much so much he wan...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked for it suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she engaged one day she walked perusing janes ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping himself carefully out wa...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have mercy gentlemen odin flung up hands dont ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      he almost choking there so much so much he wan...     3.0\n",
       "1                            sister asked for it suppose     2.0\n",
       "2      she engaged one day she walked perusing janes ...     1.0\n",
       "3      captain porch keeping himself carefully out wa...     4.0\n",
       "4      have mercy gentlemen odin flung up hands dont ...     3.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver4_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver4_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver4_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver4_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver4_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver4_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver4_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver4_X.shape, Ver4_y.shape, Ver4_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "vocab_size = 30000\n",
    "embedding_dim = 128\n",
    "max_length = 500\n",
    "padding_type='post'\n",
    "#oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #가벼운 NLP모델 생성\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.1),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start : 1\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 537ms/step - loss: 1.3609 - val_loss: 1.0124\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 507ms/step - loss: 0.7708 - val_loss: 0.7674\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 508ms/step - loss: 0.4995 - val_loss: 0.7320\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 508ms/step - loss: 0.3544 - val_loss: 0.7609\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.2760 - val_loss: 0.8571\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2265Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 510ms/step - loss: 0.2265 - val_loss: 0.9220\n",
      "Epoch 00006: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 536ms/step - loss: 1.2759 - val_loss: 1.0086\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 510ms/step - loss: 0.7133 - val_loss: 0.7749\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 509ms/step - loss: 0.4423 - val_loss: 0.7329\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.3148 - val_loss: 0.8096\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 22s 509ms/step - loss: 0.2449 - val_loss: 0.9106\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2111Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 510ms/step - loss: 0.2111 - val_loss: 0.9592\n",
      "Epoch 00006: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 540ms/step - loss: 1.3444 - val_loss: 1.0439\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.8386 - val_loss: 0.8273\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.5516 - val_loss: 0.8167\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.4140 - val_loss: 0.8332\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.3365 - val_loss: 0.8652\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2958Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.2958 - val_loss: 0.9260\n",
      "Epoch 00006: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 543ms/step - loss: 1.3798 - val_loss: 1.0269\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.7687 - val_loss: 0.7748\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 517ms/step - loss: 0.4901 - val_loss: 0.7450\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 516ms/step - loss: 0.3597 - val_loss: 0.7856\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.2875 - val_loss: 0.8868\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2393Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.2393 - val_loss: 0.9099\n",
      "Epoch 00006: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 536ms/step - loss: 1.4205 - val_loss: 1.1297\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 510ms/step - loss: 0.8198 - val_loss: 0.7620\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 509ms/step - loss: 0.5120 - val_loss: 0.6955\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 510ms/step - loss: 0.3608 - val_loss: 0.7752\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 22s 509ms/step - loss: 0.2678 - val_loss: 0.8464\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2270Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.2270 - val_loss: 0.9247\n",
      "Epoch 00006: early stopping\n",
      "end : 1\n",
      "start : 2\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 538ms/step - loss: 1.2497 - val_loss: 0.8811\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.6380 - val_loss: 0.7394\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.4115 - val_loss: 0.7591\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.3106 - val_loss: 0.8889\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2586Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.2586 - val_loss: 0.9803\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 539ms/step - loss: 1.2256 - val_loss: 0.8700\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.6292 - val_loss: 0.7496\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.4129 - val_loss: 0.8086\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.3068 - val_loss: 0.9057\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2554Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.2554 - val_loss: 0.9757\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 542ms/step - loss: 1.2962 - val_loss: 1.0167\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 516ms/step - loss: 0.6808 - val_loss: 0.7448\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.4325 - val_loss: 0.7458\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.3142 - val_loss: 0.8496\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2568Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.2568 - val_loss: 0.9765\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 538ms/step - loss: 1.2292 - val_loss: 0.9325\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 510ms/step - loss: 0.6453 - val_loss: 0.7418\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 509ms/step - loss: 0.4192 - val_loss: 0.7713\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 509ms/step - loss: 0.3070 - val_loss: 0.8960\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2497Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.2497 - val_loss: 0.9747\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 538ms/step - loss: 1.3416 - val_loss: 0.9661\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.6920 - val_loss: 0.7397\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.4393 - val_loss: 0.7772\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.3223 - val_loss: 0.8599\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2598Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.2598 - val_loss: 0.9306\n",
      "Epoch 00005: early stopping\n",
      "end : 2\n",
      "start : 3\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 537ms/step - loss: 1.3296 - val_loss: 0.8895\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.6616 - val_loss: 0.7437\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.4249 - val_loss: 0.7698\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.3099 - val_loss: 0.8616\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2488Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.2488 - val_loss: 0.9699\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 538ms/step - loss: 1.2122 - val_loss: 0.8674\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.6100 - val_loss: 0.7481\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 510ms/step - loss: 0.3978 - val_loss: 0.7736\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.3010 - val_loss: 0.9320\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2582Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.2582 - val_loss: 0.9892\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 540ms/step - loss: 1.2015 - val_loss: 0.8863\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.6841 - val_loss: 0.7455\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 510ms/step - loss: 0.4354 - val_loss: 0.7795\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.3247 - val_loss: 0.8502\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2657Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.2657 - val_loss: 0.9827\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 539ms/step - loss: 1.2485 - val_loss: 0.8609\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.6329 - val_loss: 0.7316\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 511ms/step - loss: 0.4083 - val_loss: 0.7994\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.3092 - val_loss: 0.8847\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2548Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.2548 - val_loss: 0.9957\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 541ms/step - loss: 1.1641 - val_loss: 0.8222\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.5861 - val_loss: 0.7507\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.3931 - val_loss: 0.8056\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.3030 - val_loss: 0.8865\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2485Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.2485 - val_loss: 1.0544\n",
      "Epoch 00005: early stopping\n",
      "end : 3\n",
      "start : 4\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 538ms/step - loss: 1.3241 - val_loss: 0.9491\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.6889 - val_loss: 0.6946\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.4191 - val_loss: 0.7201\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.3079 - val_loss: 0.8356\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2528Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.2528 - val_loss: 0.8976\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 541ms/step - loss: 1.2233 - val_loss: 0.9875\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.6819 - val_loss: 0.7609\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 512ms/step - loss: 0.4282 - val_loss: 0.7903\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.3105 - val_loss: 0.8421\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2491Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.2491 - val_loss: 0.9452\n",
      "Epoch 00005: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 545ms/step - loss: 1.4155 - val_loss: 1.2093\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 518ms/step - loss: 0.9051 - val_loss: 0.8551\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 519ms/step - loss: 0.5856 - val_loss: 0.7892\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 518ms/step - loss: 0.4161 - val_loss: 0.8113\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 22s 518ms/step - loss: 0.3161 - val_loss: 0.8479\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2553Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 518ms/step - loss: 0.2553 - val_loss: 0.8863\n",
      "Epoch 00006: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 541ms/step - loss: 1.2322 - val_loss: 0.8613\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.6314 - val_loss: 0.7454\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.4047 - val_loss: 0.7441\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.3091 - val_loss: 0.7947\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.2473 - val_loss: 0.8681\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2081Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.2081 - val_loss: 1.0284\n",
      "Epoch 00006: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 23s 542ms/step - loss: 1.2581 - val_loss: 0.9013\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.6386 - val_loss: 0.7006\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.4077 - val_loss: 0.7522\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 22s 513ms/step - loss: 0.3322 - val_loss: 0.8218\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2492Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 22s 514ms/step - loss: 0.2492 - val_loss: 0.8742\n",
      "Epoch 00005: early stopping\n",
      "end : 4\n"
     ]
    }
   ],
   "source": [
    "datasets = [ (Ver1_X, Ver1_test, Ver1_y), (Ver2_X, Ver2_test, Ver2_y),\n",
    "            (Ver3_X, Ver3_test, Ver3_y), (Ver4_X, Ver4_test, Ver3_y)]\n",
    "\n",
    "lstm_oof_preds = []\n",
    "lstm_test_preds = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "for number ,(X, test, y) in enumerate(datasets,1):\n",
    "    print(f'start : {number}')\n",
    "    # 토큰화\n",
    "    X_train = np.array([x for x in X['text']])\n",
    "    X_test = np.array([x for x in test['text']])\n",
    "    y = np.array(y.values)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words = vocab_size)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # 시퀸스화 + 패딩\n",
    "    train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "    tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
    "    print(trn.shape, tst.shape)\n",
    "    \n",
    "    # oof , test 저장\n",
    "    lstm_oof_pred = np.zeros((trn.shape[0], n_class))\n",
    "    lstm_test_pred = np.zeros((tst.shape[0], n_class))\n",
    "    \n",
    "    for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "        print(f'traing model for CV #{i}')\n",
    "        clf = get_model()\n",
    "        \n",
    "        es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "        \n",
    "        clf.fit(trn[i_trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
    "            epochs=200,\n",
    "            batch_size=1024,\n",
    "            callbacks=[es])\n",
    "        \n",
    "        lstm_oof_pred[i_val, :] = clf.predict(trn[i_val])\n",
    "        lstm_test_pred += clf.predict(tst) / n_fold\n",
    "        \n",
    "        del clf\n",
    "        clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    lstm_oof_preds.append(lstm_oof_pred)\n",
    "    lstm_test_preds.append(lstm_test_pred)\n",
    "        \n",
    "    print(f'end : {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver1 logloss =   0.7444\n",
      "ver1 logloss =  73.6712\n",
      "ver2 logloss =   0.7431\n",
      "ver2 logloss =  72.7765\n",
      "ver3 logloss =   0.7439\n",
      "ver3 logloss =  72.5050\n",
      "ver4 logloss =   0.7379\n",
      "ver4 logloss =  73.3213\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(lstm_oof_preds,1):\n",
    "    print(f'ver{i} logloss = {log_loss(pd.get_dummies(y),j):8.4f}')\n",
    "    print(f'ver{i} accuracy = {accuracy_score(y, np.argmax(j,axis=1))*100:8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 파일 및 기타 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 파일 생성\n",
    "\n",
    "sub = pd.read_csv(sample_file,index_col=0)\n",
    "\n",
    "# Ver1 \n",
    "sub[sub.columns] = lstm_test_preds[0]\n",
    "sub.to_csv(lstm_submission_ver1_file)\n",
    "\n",
    "# Ver2\n",
    "sub[sub.columns] = lstm_test_preds[1]\n",
    "sub.to_csv(lstm_submission_ver2_file)\n",
    "\n",
    "# Ver3\n",
    "sub[sub.columns] = lstm_test_preds[2]\n",
    "sub.to_csv(lstm_submission_ver3_file)\n",
    "           \n",
    "# Ver4\n",
    "sub[sub.columns] = lstm_test_preds[3]\n",
    "sub.to_csv(lstm_submission_ver4_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_oof_pred 파일 생성\n",
    "\n",
    "# Ver1\n",
    "np.savetxt(lstm_oof_pred_ver1_file, lstm_oof_preds[0],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver2\n",
    "np.savetxt(lstm_oof_pred_ver2_file, lstm_oof_preds[1],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver3\n",
    "np.savetxt(lstm_oof_pred_ver3_file, lstm_oof_preds[2],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver4\n",
    "np.savetxt(lstm_oof_pred_ver4_file, lstm_oof_preds[3],fmt='%.18f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_test_pred 파일 생성\n",
    "\n",
    "# Ver1\n",
    "np.savetxt(lstm_test_pred_ver1_file, lstm_test_preds[0],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver2\n",
    "np.savetxt(lstm_test_pred_ver2_file, lstm_test_preds[1],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver3\n",
    "np.savetxt(lstm_test_pred_ver3_file, lstm_test_preds[2],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver4\n",
    "np.savetxt(lstm_test_pred_ver4_file, lstm_test_preds[3],fmt='%.18f', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
