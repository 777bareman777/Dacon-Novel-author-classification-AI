{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from matplotlib import rcParams, pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "# np.random.seed(seed)\n",
    "# rn.seed(seed)\n",
    "# tf.random.set_seed(seed)\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "#                              inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/dacon-novel-author-classification')\n",
    "feature_dir = Path('../build/feature')\n",
    "val_dir = Path('../build/val')\n",
    "tst_dir = Path('../build/tst')\n",
    "sub_dir = Path('../build/sub')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_name = 'cnn'\n",
    "feature_name = 'feature'\n",
    "model_name = f'{algorithm_name}_{feature_name}'\n",
    "\n",
    "feature_Ver1_file = feature_dir / f'{feature_name}_Ver1.csv'\n",
    "feature_Ver2_file = feature_dir / f'{feature_name}_Ver2.csv'\n",
    "feature_Ver3_file = feature_dir / f'{feature_name}_Ver3.csv'\n",
    "feature_Ver4_file = feature_dir / f'{feature_name}_Ver4.csv'\n",
    "\n",
    "\n",
    "cnn_oof_pred_ver1_file = val_dir / f'{model_name}_oof_pred_ver1.csv'\n",
    "cnn_oof_pred_ver2_file = val_dir / f'{model_name}_oof_pred_ver2.csv'\n",
    "cnn_oof_pred_ver3_file = val_dir / f'{model_name}_oof_pred_ver3.csv'\n",
    "cnn_oof_pred_ver4_file = val_dir / f'{model_name}_oof_pred_ver4.csv'\n",
    "\n",
    "\n",
    "cnn_test_pred_ver1_file = tst_dir / f'{model_name}_test_pred_ver1.csv'\n",
    "cnn_test_pred_ver2_file = tst_dir / f'{model_name}_test_pred_ver2.csv'\n",
    "cnn_test_pred_ver3_file = tst_dir / f'{model_name}_test_pred_ver3.csv'\n",
    "cnn_test_pred_ver4_file = tst_dir / f'{model_name}_test_pred_ver4.csv'\n",
    "\n",
    "\n",
    "cnn_submission_ver1_file = sub_dir / f'{model_name}_submission_Ver1.csv'\n",
    "cnn_submission_ver2_file = sub_dir / f'{model_name}_submission_Ver2.csv'\n",
    "cnn_submission_ver3_file = sub_dir / f'{model_name}_submission_Ver3.csv'\n",
    "cnn_submission_ver4_file = sub_dir / f'{model_name}_submission_Ver4.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver 1 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he was almost choking there was so much so muc...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your sister asked for it i suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she was engaged one day as she walked in peru...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the captain was in the porch keeping himself c...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have mercy gentlemen odin flung up his hands d...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      he was almost choking there was so much so muc...     3.0\n",
       "1                     your sister asked for it i suppose     2.0\n",
       "2       she was engaged one day as she walked in peru...     1.0\n",
       "3      the captain was in the porch keeping himself c...     4.0\n",
       "4      have mercy gentlemen odin flung up his hands d...     3.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver1_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver1_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver1_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver1_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver1_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver1_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver1_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver1_X.shape, Ver1_y.shape, Ver1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver 2 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost choking much much wanted say strange ex...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engaged one day walked perusing janes last let...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping carefully way treacherou...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mercy gentlemen odin flung hands dont write an...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      almost choking much much wanted say strange ex...     3.0\n",
       "1                                   sister asked suppose     2.0\n",
       "2      engaged one day walked perusing janes last let...     1.0\n",
       "3      captain porch keeping carefully way treacherou...     4.0\n",
       "4      mercy gentlemen odin flung hands dont write an...     3.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver2_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver2_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver2_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver2_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver2_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver2_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver2_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver2_X.shape, Ver2_y.shape, Ver2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver3 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost choking much much wanted say strange ex...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engaged day walked perusing janes last letter ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping himself carefully out wa...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mercy gentlemen flung up hands dont write anyw...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      almost choking much much wanted say strange ex...     3.0\n",
       "1                                   sister asked suppose     2.0\n",
       "2      engaged day walked perusing janes last letter ...     1.0\n",
       "3      captain porch keeping himself carefully out wa...     4.0\n",
       "4      mercy gentlemen flung up hands dont write anyw...     3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver3_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver3_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver3_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver3_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver3_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver3_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver3_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver3_X.shape, Ver3_y.shape, Ver3_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver4 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74496, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he almost choking there so much so much he wan...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister asked for it suppose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she engaged one day she walked perusing janes ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping himself carefully out wa...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have mercy gentlemen odin flung up hands dont ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      he almost choking there so much so much he wan...     3.0\n",
       "1                            sister asked for it suppose     2.0\n",
       "2      she engaged one day she walked perusing janes ...     1.0\n",
       "3      captain porch keeping himself carefully out wa...     4.0\n",
       "4      have mercy gentlemen odin flung up hands dont ...     3.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(feature_Ver4_file, index_col=0)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 1) (54879,) (19617, 1)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "Ver4_X = dataset.loc[dataset[target_col] != -1 , :]\n",
    "Ver4_X.drop(columns=target_col,inplace=True,axis=1)\n",
    "Ver4_y = dataset.loc[dataset[target_col] != -1, target_col]\n",
    "Ver4_y.astype(int)\n",
    "\n",
    "# test set\n",
    "Ver4_test = dataset.loc[dataset[target_col] == -1, :]\n",
    "Ver4_test.drop(columns=target_col, inplace=True,axis=1)\n",
    "\n",
    "print(Ver4_X.shape, Ver4_y.shape, Ver4_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "vocab_size = 30000\n",
    "embedding_dim = 128\n",
    "max_length = 500\n",
    "padding_type='post'\n",
    "#oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        Dropout(.5),\n",
    "        Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3),\n",
    "        Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3),    \n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(.5),\n",
    "        Dense(n_class, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=.0003))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start : 1\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 1.5767 - val_loss: 1.5739\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5650 - val_loss: 1.5606\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.5241 - val_loss: 1.4717\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4192 - val_loss: 1.3082\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.2015 - val_loss: 1.0807\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.0125 - val_loss: 0.9669\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.8909 - val_loss: 0.9018\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.8013 - val_loss: 0.8659\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7313 - val_loss: 0.8385\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6732 - val_loss: 0.8251\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6211 - val_loss: 0.8249\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5790 - val_loss: 0.8196\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.5433 - val_loss: 0.8240\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5078 - val_loss: 0.8221\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4749Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4749 - val_loss: 0.8285\n",
      "Epoch 00015: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 164ms/step - loss: 1.5765 - val_loss: 1.5759\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5636 - val_loss: 1.5548\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5208 - val_loss: 1.4841\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4388 - val_loss: 1.3967\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3181 - val_loss: 1.2192\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1074 - val_loss: 1.0431\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9478 - val_loss: 0.9446\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8363 - val_loss: 0.8898\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.7526 - val_loss: 0.8536\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6790 - val_loss: 0.8346\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6235 - val_loss: 0.8195\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5707 - val_loss: 0.8050\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5270 - val_loss: 0.8043\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4900 - val_loss: 0.8097\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4580Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4580 - val_loss: 0.8145\n",
      "Epoch 00015: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 1.5781 - val_loss: 1.5737\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5656 - val_loss: 1.5545\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5169 - val_loss: 1.4630\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4418 - val_loss: 1.3948\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.3431 - val_loss: 1.2903\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.2338 - val_loss: 1.1874\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.0953 - val_loss: 1.0602\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.9721 - val_loss: 0.9785\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8673 - val_loss: 0.9203\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7815 - val_loss: 0.8781\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7135 - val_loss: 0.8439\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6505 - val_loss: 0.8379\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5950 - val_loss: 0.8185\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5449 - val_loss: 0.8025\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5061 - val_loss: 0.8036\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4625 - val_loss: 0.8094\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4296Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4296 - val_loss: 0.8130\n",
      "Epoch 00017: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 164ms/step - loss: 1.5760 - val_loss: 1.5758\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5658 - val_loss: 1.5559\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5303 - val_loss: 1.4859\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4581 - val_loss: 1.4261\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.3591 - val_loss: 1.2502\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1282 - val_loss: 1.0160\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9421 - val_loss: 0.9252\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.8214 - val_loss: 0.8655\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7295 - val_loss: 0.8263\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6550 - val_loss: 0.8026\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5914 - val_loss: 0.7884\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5455 - val_loss: 0.7807\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5004 - val_loss: 0.7837\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4630 - val_loss: 0.7903\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4343Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4343 - val_loss: 0.8012\n",
      "Epoch 00015: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 167ms/step - loss: 1.5772 - val_loss: 1.5760\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5683 - val_loss: 1.5662\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5404 - val_loss: 1.4978\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4692 - val_loss: 1.4318\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3870 - val_loss: 1.3266\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.2085 - val_loss: 1.0829\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.9774 - val_loss: 0.9297\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8302 - val_loss: 0.8480\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7271 - val_loss: 0.8021\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6525 - val_loss: 0.7752\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5867 - val_loss: 0.7610\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5406 - val_loss: 0.7595\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5014 - val_loss: 0.7570\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4627 - val_loss: 0.7671\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4320 - val_loss: 0.7723\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4057Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 0.4057 - val_loss: 0.7803\n",
      "Epoch 00016: early stopping\n",
      "end : 1\n",
      "start : 2\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 1.5776 - val_loss: 1.5730\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5703 - val_loss: 1.5644\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5425 - val_loss: 1.4880\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4277 - val_loss: 1.3526\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 1.3004 - val_loss: 1.2489\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1462 - val_loss: 1.0778\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9756 - val_loss: 0.9738\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.8499 - val_loss: 0.9086\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7487 - val_loss: 0.8809\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6769 - val_loss: 0.8777\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6209 - val_loss: 0.8672\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5687 - val_loss: 0.8709\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5282 - val_loss: 0.8878\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4974Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4974 - val_loss: 0.8883\n",
      "Epoch 00014: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 1.5786 - val_loss: 1.5716\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5679 - val_loss: 1.5634\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5363 - val_loss: 1.4952\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.4530 - val_loss: 1.4114\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3788 - val_loss: 1.3746\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3091 - val_loss: 1.3087\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.2132 - val_loss: 1.2482\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.0855 - val_loss: 1.1029\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9265 - val_loss: 0.9874\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7985 - val_loss: 0.9167\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6953 - val_loss: 0.8714\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6137 - val_loss: 0.8575\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5495 - val_loss: 0.8526\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5036 - val_loss: 0.8564\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4641 - val_loss: 0.8679\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4300Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4300 - val_loss: 0.8707\n",
      "Epoch 00016: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 1.5783 - val_loss: 1.5753\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5698 - val_loss: 1.5664\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5385 - val_loss: 1.4842\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.4284 - val_loss: 1.3532\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.3076 - val_loss: 1.2686\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.2078 - val_loss: 1.2138\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1211 - val_loss: 1.1617\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.0246 - val_loss: 1.0830\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9179 - val_loss: 1.0252\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.8309 - val_loss: 0.9923\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7556 - val_loss: 0.9913\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6921 - val_loss: 0.9795\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6370 - val_loss: 0.9799\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5879 - val_loss: 0.9840\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5400Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5400 - val_loss: 0.9977\n",
      "Epoch 00015: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 164ms/step - loss: 1.5765 - val_loss: 1.5736\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5652 - val_loss: 1.5516\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5128 - val_loss: 1.4430\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3860 - val_loss: 1.3244\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.2752 - val_loss: 1.2573\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.1758 - val_loss: 1.1798\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.0517 - val_loss: 1.0548\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.9229 - val_loss: 0.9733\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8153 - val_loss: 0.9402\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7377 - val_loss: 0.9289\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6694 - val_loss: 0.9230\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6242 - val_loss: 0.9276\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5835 - val_loss: 0.9358\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5356Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5356 - val_loss: 0.9549\n",
      "Epoch 00014: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 1.5753 - val_loss: 1.5782\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.5679 - val_loss: 1.5644\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5379 - val_loss: 1.4896\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.4372 - val_loss: 1.3684\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3099 - val_loss: 1.2728\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1811 - val_loss: 1.1533\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.0193 - val_loss: 1.0271\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.8898 - val_loss: 0.9546\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7848 - val_loss: 0.9100\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6949 - val_loss: 0.8846\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6281 - val_loss: 0.8686\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5715 - val_loss: 0.8613\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5212 - val_loss: 0.8658\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4743 - val_loss: 0.8776\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4414Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4414 - val_loss: 0.8792\n",
      "Epoch 00015: early stopping\n",
      "end : 2\n",
      "start : 3\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 164ms/step - loss: 1.5772 - val_loss: 1.5761\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5666 - val_loss: 1.5562\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 1.5115 - val_loss: 1.4318\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3680 - val_loss: 1.3193\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.2631 - val_loss: 1.2456\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 1.1754 - val_loss: 1.1980\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.0891 - val_loss: 1.1247\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.9878 - val_loss: 1.0587\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8967 - val_loss: 1.0247\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.8187 - val_loss: 1.0058\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7561 - val_loss: 0.9965\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6956 - val_loss: 0.9842\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6433 - val_loss: 0.9840\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5919 - val_loss: 0.9901\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5540Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 0.5540 - val_loss: 1.0043\n",
      "Epoch 00015: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 1.5784 - val_loss: 1.5771\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5679 - val_loss: 1.5647\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.5387 - val_loss: 1.5013\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4456 - val_loss: 1.4034\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.3433 - val_loss: 1.3257\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.2490 - val_loss: 1.2582\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1550 - val_loss: 1.1938\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.0478 - val_loss: 1.1229\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.9427 - val_loss: 1.0502\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8418 - val_loss: 1.0028\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7566 - val_loss: 0.9769\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6823 - val_loss: 0.9473\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6088 - val_loss: 0.9363\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5587 - val_loss: 0.9312\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5080 - val_loss: 0.9313\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4677 - val_loss: 0.9462\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4365Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4365 - val_loss: 0.9385\n",
      "Epoch 00017: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 164ms/step - loss: 1.5781 - val_loss: 1.5737\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5708 - val_loss: 1.5712\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5541 - val_loss: 1.5167\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.4682 - val_loss: 1.4031\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.3659 - val_loss: 1.3258\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.2450 - val_loss: 1.2114\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1256 - val_loss: 1.1507\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.0217 - val_loss: 1.0709\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.9204 - val_loss: 1.0290\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8367 - val_loss: 0.9960\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7592 - val_loss: 0.9740\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6894 - val_loss: 0.9498\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6205 - val_loss: 0.9302\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5635 - val_loss: 0.9155\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5110 - val_loss: 0.9076\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4660 - val_loss: 0.9214\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 0.4350 - val_loss: 0.9299\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4097Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4097 - val_loss: 0.9461\n",
      "Epoch 00018: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 1.5777 - val_loss: 1.5793\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.5713 - val_loss: 1.5726\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.5581 - val_loss: 1.5354\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4740 - val_loss: 1.3944\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.3411 - val_loss: 1.2928\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.2205 - val_loss: 1.2091\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1237 - val_loss: 1.1575\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.0359 - val_loss: 1.1069\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.9376 - val_loss: 1.0399\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8385 - val_loss: 0.9878\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7539 - val_loss: 0.9583\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6774 - val_loss: 0.9248\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.6047 - val_loss: 0.9026\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5444 - val_loss: 0.8960\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4927 - val_loss: 0.8989\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4515 - val_loss: 0.9054\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4187Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4187 - val_loss: 0.9144\n",
      "Epoch 00017: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 1.5779 - val_loss: 1.5761\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5711 - val_loss: 1.5725\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5575 - val_loss: 1.5275\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.4712 - val_loss: 1.3998\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3482 - val_loss: 1.3026\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.2318 - val_loss: 1.2142\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1114 - val_loss: 1.1109\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9814 - val_loss: 1.0319\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8793 - val_loss: 0.9897\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7960 - val_loss: 0.9653\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7220 - val_loss: 0.9454\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6514 - val_loss: 0.9359\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5906 - val_loss: 0.9244\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5373 - val_loss: 0.9189\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.4906 - val_loss: 0.9178\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4503 - val_loss: 0.9311\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.4209 - val_loss: 0.9384\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3913Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.3913 - val_loss: 0.9504\n",
      "Epoch 00018: early stopping\n",
      "end : 3\n",
      "start : 4\n",
      "(54879, 500) (19617, 500)\n",
      "traing model for CV #1\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 165ms/step - loss: 1.5772 - val_loss: 1.5730\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5678 - val_loss: 1.5597\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.5296 - val_loss: 1.4717\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.4267 - val_loss: 1.3574\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.2734 - val_loss: 1.1778\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.0867 - val_loss: 1.0510\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9511 - val_loss: 0.9727\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8543 - val_loss: 0.9099\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7716 - val_loss: 0.8706\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.7044 - val_loss: 0.8400\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6410 - val_loss: 0.8101\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5760 - val_loss: 0.7930\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5218 - val_loss: 0.7797\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4685 - val_loss: 0.7733\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.4316 - val_loss: 0.7756\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.3981 - val_loss: 0.7883\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3699Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.3699 - val_loss: 0.7946\n",
      "Epoch 00017: early stopping\n",
      "traing model for CV #2\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 165ms/step - loss: 1.5778 - val_loss: 1.5728\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5621 - val_loss: 1.5455\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.5031 - val_loss: 1.4603\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4195 - val_loss: 1.3835\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.3319 - val_loss: 1.2996\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.2153 - val_loss: 1.1610\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.0303 - val_loss: 0.9921\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8591 - val_loss: 0.8967\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7476 - val_loss: 0.8432\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6633 - val_loss: 0.8193\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5909 - val_loss: 0.7994\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5367 - val_loss: 0.7926\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4907 - val_loss: 0.8010\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4543 - val_loss: 0.8067\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4182Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4182 - val_loss: 0.8154\n",
      "Epoch 00015: early stopping\n",
      "traing model for CV #3\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 1.5788 - val_loss: 1.5755\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5690 - val_loss: 1.5613\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5331 - val_loss: 1.4818\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.4495 - val_loss: 1.3990\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.3141 - val_loss: 1.1872\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.0948 - val_loss: 1.0169\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9454 - val_loss: 0.9404\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8448 - val_loss: 0.8976\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.7704 - val_loss: 0.8713\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7087 - val_loss: 0.8439\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6591 - val_loss: 0.8433\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6180 - val_loss: 0.8322\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.5777 - val_loss: 0.8247\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5364 - val_loss: 0.8166\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4903 - val_loss: 0.8160\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.4501 - val_loss: 0.8180\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4097Restoring model weights from the end of the best epoch.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4097 - val_loss: 0.8288\n",
      "Epoch 00017: early stopping\n",
      "traing model for CV #4\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 164ms/step - loss: 1.5767 - val_loss: 1.5725\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5653 - val_loss: 1.5479\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5064 - val_loss: 1.4522\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.4175 - val_loss: 1.3720\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.2920 - val_loss: 1.1786\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 1.0610 - val_loss: 0.9924\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9059 - val_loss: 0.9210\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8080 - val_loss: 0.8759\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.7312 - val_loss: 0.8469\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6651 - val_loss: 0.8215\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6061 - val_loss: 0.8087\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.5520 - val_loss: 0.8026\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.5076 - val_loss: 0.7996\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4732 - val_loss: 0.8068\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.4392 - val_loss: 0.8156\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4069Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4069 - val_loss: 0.8316\n",
      "Epoch 00016: early stopping\n",
      "traing model for CV #5\n",
      "Epoch 1/200\n",
      "43/43 [==============================] - 7s 164ms/step - loss: 1.5760 - val_loss: 1.5727\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5662 - val_loss: 1.5534\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.5141 - val_loss: 1.4630\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.4314 - val_loss: 1.4074\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.3552 - val_loss: 1.3232\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 1.2551 - val_loss: 1.2354\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 1.1047 - val_loss: 1.0705\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.9531 - val_loss: 0.9930\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.8490 - val_loss: 0.9275\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.7595 - val_loss: 0.8817\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6804 - val_loss: 0.8441\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.6070 - val_loss: 0.8117\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.5454 - val_loss: 0.7936\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4919 - val_loss: 0.7902\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4490 - val_loss: 0.7993\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.4161 - val_loss: 0.8059\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.3911Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.3911 - val_loss: 0.8122\n",
      "Epoch 00017: early stopping\n",
      "end : 4\n"
     ]
    }
   ],
   "source": [
    "datasets = [ (Ver1_X, Ver1_test, Ver1_y), (Ver2_X, Ver2_test, Ver2_y),\n",
    "            (Ver3_X, Ver3_test, Ver3_y), (Ver4_X, Ver4_test, Ver3_y)]\n",
    "\n",
    "cnn_oof_preds = []\n",
    "cnn_test_preds = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "for number ,(X, test, y) in enumerate(datasets,1):\n",
    "    print(f'start : {number}')\n",
    "    # 토큰화\n",
    "    X_train = np.array([x for x in X['text']])\n",
    "    X_test = np.array([x for x in test['text']])\n",
    "    y = np.array(y.values)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words = vocab_size)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # 시퀸스화 + 패딩\n",
    "    train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "    tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
    "    print(trn.shape, tst.shape)\n",
    "    \n",
    "    # oof , test 저장\n",
    "    cnn_oof_pred = np.zeros((trn.shape[0], n_class))\n",
    "    cnn_test_pred = np.zeros((tst.shape[0], n_class))\n",
    "    \n",
    "    for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "        print(f'traing model for CV #{i}')\n",
    "        clf = get_model()\n",
    "        \n",
    "        es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "        \n",
    "        rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                            patience=3, min_lr=1e-6, mode='min', verbose=1)\n",
    "        \n",
    "        clf.fit(trn[i_trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
    "            epochs=200,\n",
    "            batch_size=1024,\n",
    "            callbacks=[es, rlr])\n",
    "        \n",
    "        cnn_oof_pred[i_val, :] = clf.predict(trn[i_val])\n",
    "        cnn_test_pred += clf.predict(tst) / n_fold\n",
    "        \n",
    "        del clf\n",
    "        clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    cnn_oof_preds.append(cnn_oof_pred)\n",
    "    cnn_test_preds.append(cnn_test_pred)\n",
    "        \n",
    "    print(f'end : {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver1 logloss =   0.7930\n",
      "ver1 logloss =  70.9925\n",
      "ver2 logloss =   0.8967\n",
      "ver2 logloss =  66.5391\n",
      "ver3 logloss =   0.9273\n",
      "ver3 logloss =  66.9564\n",
      "ver4 logloss =   0.7945\n",
      "ver4 logloss =  71.5611\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(cnn_oof_preds,1):\n",
    "    print(f'ver{i} logloss = {log_loss(pd.get_dummies(y),j):8.4f}')\n",
    "    print(f'ver{i} accuracy = {accuracy_score(y, np.argmax(j,axis=1))*100:8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 파일 및 기타 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 파일 생성\n",
    "\n",
    "sub = pd.read_csv(sample_file,index_col=0)\n",
    "\n",
    "# Ver1 \n",
    "sub[sub.columns] = cnn_test_preds[0]\n",
    "sub.to_csv(cnn_submission_ver1_file)\n",
    "\n",
    "# Ver2\n",
    "sub[sub.columns] = cnn_test_preds[1]\n",
    "sub.to_csv(cnn_submission_ver2_file)\n",
    "\n",
    "# Ver3\n",
    "sub[sub.columns] = cnn_test_preds[2]\n",
    "sub.to_csv(cnn_submission_ver3_file)\n",
    "           \n",
    "# Ver4\n",
    "sub[sub.columns] = cnn_test_preds[3]\n",
    "sub.to_csv(cnn_submission_ver4_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_oof_pred 파일 생성\n",
    "\n",
    "# Ver1\n",
    "np.savetxt(cnn_oof_pred_ver1_file, cnn_oof_preds[0],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver2\n",
    "np.savetxt(cnn_oof_pred_ver2_file, cnn_oof_preds[1],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver3\n",
    "np.savetxt(cnn_oof_pred_ver3_file, cnn_oof_preds[2],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver4\n",
    "np.savetxt(cnn_oof_pred_ver4_file, cnn_oof_preds[3],fmt='%.18f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_test_pred 파일 생성\n",
    "\n",
    "# Ver1\n",
    "np.savetxt(cnn_test_pred_ver1_file, cnn_test_preds[0],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver2\n",
    "np.savetxt(cnn_test_pred_ver2_file, cnn_test_preds[1],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver3\n",
    "np.savetxt(cnn_test_pred_ver3_file, cnn_test_preds[2],fmt='%.18f', delimiter=',')\n",
    "\n",
    "# Ver4\n",
    "np.savetxt(cnn_test_pred_ver4_file, cnn_test_preds[3],fmt='%.18f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
