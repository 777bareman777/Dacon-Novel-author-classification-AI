{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데모"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufcGB_euCc7M"
   },
   "source": [
    "## 라이브러리 import 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:21.154348Z",
     "start_time": "2020-11-11T09:33:20.735954Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:24.850245Z",
     "start_time": "2020-11-11T09:33:21.156444Z"
    },
    "id": "TmA1Au6CCaC7"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from matplotlib import rcParams, pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_hub as hub\n",
    "# import tokenization\n",
    "# from bert import tokenization\n",
    "from bert import bert_tokenization\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:24.906249Z",
     "start_time": "2020-11-11T09:33:24.852607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:24.952870Z",
     "start_time": "2020-11-11T09:33:24.908314Z"
    }
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Tokenizer 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:24.999676Z",
     "start_time": "2020-11-11T09:33:24.954982Z"
    },
    "id": "0ZwTCLUOCtUu"
   },
   "outputs": [],
   "source": [
    "data_dir = Path('../data/dacon-novel-author-classification')\n",
    "feature_dir = Path('../build/feature')\n",
    "val_dir = Path('../build/val')\n",
    "tst_dir = Path('../build/tst')\n",
    "sub_dir = Path('../build/sub')\n",
    "dirs = [feature_dir, val_dir, tst_dir, sub_dir]\n",
    "for d in dirs:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "module_url = \"./export_dir/\"\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:25.044366Z",
     "start_time": "2020-11-11T09:33:25.001407Z"
    }
   },
   "outputs": [],
   "source": [
    "algo_name = 'bert'\n",
    "max_len = 100\n",
    "feature_name = f'n{max_len}'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv'\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "sub_file = sub_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:36.513765Z",
     "start_time": "2020-11-11T09:33:25.046192Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_layer = hub.KerasLayer(module_url, trainable=True)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "# tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenization 라이브러리에 FullTokenizer가 없어서\n",
    "bert-for-tf2 라이브러리르 설치해서 해결함.\n",
    "\n",
    "참고 사이트\n",
    "https://github.com/google-research/bert/issues/638"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:36.725491Z",
     "start_time": "2020-11-11T09:33:36.517201Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "SvX_U2ETC7vA",
    "outputId": "25b26c45-fe51-42b4-b55d-eaddea79fd94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      He was almost choking. There was so much, so m...       3\n",
       "1                 “Your sister asked for it, I suppose?”       2\n",
       "2       She was engaged one day as she walked, in per...       1\n",
       "3      The captain was in the porch, keeping himself ...       4\n",
       "4      “Have mercy, gentlemen!” odin flung up his han...       3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(trn_file, index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:36.853668Z",
     "start_time": "2020-11-11T09:33:36.727797Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "8MxZsr6yCshr",
    "outputId": "e8a76d96-2fde-4796-be03-7e3cdf4f9ff4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Not at all. I think she is one of the most ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the lady had stated her intention of scream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“And then suddenly in the silence I heard a so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His conviction remained unchanged. So far as I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "index                                                   \n",
       "0      “Not at all. I think she is one of the most ch...\n",
       "1      \"No,\" replied he, with sudden consciousness, \"...\n",
       "2      As the lady had stated her intention of scream...\n",
       "3      “And then suddenly in the silence I heard a so...\n",
       "4      His conviction remained unchanged. So far as I..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(tst_file, index_col=0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPq0vxJVDS3R"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:33:36.903042Z",
     "start_time": "2020-11-11T09:33:36.855555Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n",
    "def bert_encode(texts, tokenizer, max_len=max_len):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:34:38.960578Z",
     "start_time": "2020-11-11T09:33:36.904937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 100) (19617, 100) (54879,)\n"
     ]
    }
   ],
   "source": [
    "trn = bert_encode(train.text.values, tokenizer, max_len=max_len)\n",
    "tst = bert_encode(test.text.values, tokenizer, max_len=max_len)\n",
    "y = train['author'].values\n",
    "print(trn[0].shape, tst[0].shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks1FhSNUHrke"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:34:39.014168Z",
     "start_time": "2020-11-11T09:34:38.962280Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(bert_layer, max_len=max_len):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    x = Dense(256, activation='relu')(clf_output)\n",
    "    out = Dense(n_class, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:34:39.065020Z",
     "start_time": "2020-11-11T09:34:39.016433Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T09:33:20.754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 256), (None, 9363969     input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 256)]        0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          65792       tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            1285        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 9,431,046\n",
      "Trainable params: 9,431,045\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.4814 - accuracy: 0.3134 - val_loss: 0.4386 - val_accuracy: 0.4354\n",
      "Epoch 2/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.4081 - accuracy: 0.4959 - val_loss: 0.3774 - val_accuracy: 0.5479\n",
      "Epoch 3/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.3514 - accuracy: 0.5977 - val_loss: 0.3404 - val_accuracy: 0.6146\n",
      "Epoch 4/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.3115 - accuracy: 0.6546 - val_loss: 0.3106 - val_accuracy: 0.6481\n",
      "Epoch 5/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2825 - accuracy: 0.6905 - val_loss: 0.3007 - val_accuracy: 0.6645\n",
      "Epoch 6/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2592 - accuracy: 0.7203 - val_loss: 0.2918 - val_accuracy: 0.6787\n",
      "Epoch 7/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2397 - accuracy: 0.7429 - val_loss: 0.2912 - val_accuracy: 0.6850\n",
      "Epoch 8/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2242 - accuracy: 0.7615 - val_loss: 0.2920 - val_accuracy: 0.6893\n",
      "Epoch 9/200\n",
      "2744/2744 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.7750Restoring model weights from the end of the best epoch.\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2118 - accuracy: 0.7750 - val_loss: 0.2911 - val_accuracy: 0.6903\n",
      "Epoch 00009: early stopping\n",
      "training model for CV #2\n",
      "Epoch 1/200\n",
      "2744/2744 [==============================] - 70s 26ms/step - loss: 0.2883 - accuracy: 0.7001 - val_loss: 0.2361 - val_accuracy: 0.7530\n",
      "Epoch 2/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2432 - accuracy: 0.7441 - val_loss: 0.2289 - val_accuracy: 0.7544\n",
      "Epoch 3/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2251 - accuracy: 0.7599 - val_loss: 0.2337 - val_accuracy: 0.7477\n",
      "Epoch 4/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2122 - accuracy: 0.7749 - val_loss: 0.2342 - val_accuracy: 0.7459\n",
      "Epoch 5/200\n",
      "2742/2744 [============================>.] - ETA: 0s - loss: 0.2002 - accuracy: 0.7892Restoring model weights from the end of the best epoch.\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2002 - accuracy: 0.7892 - val_loss: 0.2405 - val_accuracy: 0.7419\n",
      "Epoch 00005: early stopping\n",
      "training model for CV #3\n",
      "Epoch 1/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2599 - accuracy: 0.7354 - val_loss: 0.2027 - val_accuracy: 0.7919\n",
      "Epoch 2/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2220 - accuracy: 0.7674 - val_loss: 0.2030 - val_accuracy: 0.7851\n",
      "Epoch 3/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2085 - accuracy: 0.7814 - val_loss: 0.2073 - val_accuracy: 0.7775\n",
      "Epoch 4/200\n",
      "2744/2744 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.7920Restoring model weights from the end of the best epoch.\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.1974 - accuracy: 0.7920 - val_loss: 0.2130 - val_accuracy: 0.7731\n",
      "Epoch 00004: early stopping\n",
      "training model for CV #4\n",
      "Epoch 1/200\n",
      "2744/2744 [==============================] - 70s 25ms/step - loss: 0.2454 - accuracy: 0.7547 - val_loss: 0.1980 - val_accuracy: 0.7956\n",
      "Epoch 2/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2129 - accuracy: 0.7756 - val_loss: 0.1968 - val_accuracy: 0.7925\n",
      "Epoch 3/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.2004 - accuracy: 0.7897 - val_loss: 0.2040 - val_accuracy: 0.7820\n",
      "Epoch 4/200\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.1898 - accuracy: 0.7989 - val_loss: 0.2073 - val_accuracy: 0.7785\n",
      "Epoch 5/200\n",
      "2743/2744 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.8099Restoring model weights from the end of the best epoch.\n",
      "2744/2744 [==============================] - 69s 25ms/step - loss: 0.1813 - accuracy: 0.8100 - val_loss: 0.2149 - val_accuracy: 0.7772\n",
      "Epoch 00005: early stopping\n",
      "training model for CV #5\n",
      "Epoch 1/200\n",
      "2744/2744 [==============================] - 64s 23ms/step - loss: 0.2378 - accuracy: 0.7621 - val_loss: 0.1840 - val_accuracy: 0.8087\n",
      "Epoch 2/200\n",
      "2744/2744 [==============================] - 64s 23ms/step - loss: 0.2000 - accuracy: 0.7912 - val_loss: 0.1865 - val_accuracy: 0.7985\n",
      "Epoch 3/200\n",
      "2744/2744 [==============================] - 64s 23ms/step - loss: 0.1884 - accuracy: 0.8030 - val_loss: 0.1869 - val_accuracy: 0.7979\n",
      "Epoch 4/200\n",
      "2743/2744 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.8124Restoring model weights from the end of the best epoch.\n",
      "2744/2744 [==============================] - 64s 23ms/step - loss: 0.1799 - accuracy: 0.8124 - val_loss: 0.1990 - val_accuracy: 0.7877\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "p_val = np.zeros((trn[0].shape[0], n_class))\n",
    "p_tst = np.zeros((tst[0].shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(trn[0], y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "    \n",
    "    clf = get_model(bert_layer, max_len=max_len)\n",
    "    if i == 1:\n",
    "        print(clf.summary())\n",
    "        \n",
    "    clf.fit([x[i_trn] for x in trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=([x[i_val] for x in trn], to_categorical(y[i_val])),\n",
    "            epochs=200,\n",
    "            batch_size=16,\n",
    "           callbacks=[es])\n",
    "    p_val[i_val, :] = clf.predict([x[i_val] for x in trn])\n",
    "    p_tst += clf.predict(tst) / n_fold\n",
    "    \n",
    "    del clf\n",
    "    clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T09:33:20.756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CV):  76.5229%\n",
      "Log Loss (CV):   0.6523\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
    "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T09:33:20.758Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T09:33:20.762Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jXKoOWIC6g0",
    "outputId": "620417f7-087d-4f0f-e6c6-34af5484880c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19617, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4\n",
       "index               \n",
       "0      0  0  0  0  0\n",
       "1      0  0  0  0  0\n",
       "2      0  0  0  0  0\n",
       "3      0  0  0  0  0\n",
       "4      0  0  0  0  0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(sample_file, index_col=0)\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T09:33:20.763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4S8eUx5FDFO",
    "outputId": "e31d03c3-b143-4922-ccb6-a6f9fcf02efc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.2654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9513</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.6802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4\n",
       "index                                        \n",
       "0      0.0066  0.8597  0.2099  0.0151  0.0055\n",
       "1      0.2415  0.3965  0.0019  0.0028  0.2654\n",
       "2      0.9513  0.0414  0.0032  0.0025  0.0150\n",
       "3      0.0227  0.0139  0.9618  0.0127  0.0210\n",
       "4      0.2322  0.0635  0.0044  0.0294  0.6802"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[sub.columns] = p_tst\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T09:33:20.764Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "tZhbUjhXE3Yr",
    "outputId": "6642ce6e-22c5-4f87-a4f1-5bdae56abaad"
   },
   "outputs": [],
   "source": [
    "sub.to_csv(sub_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sample_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
